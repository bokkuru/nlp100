{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter09-3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KTqxPKVEejRt",
        "KydwtwMyg-e7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG-o-2PXw8ks",
        "colab_type": "text"
      },
      "source": [
        "# 問題80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY4H45kQxAgN",
        "colab_type": "text"
      },
      "source": [
        "問題51の再現"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rov4MrwKwyPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4906c61c-9ac9-45b6-9c7f-3d890397e8f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_root_dir=\"./drive/My Drive\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfLdhBWS12xX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "1493cf56-c3af-4564-9a2b-631ca4ed440d"
      },
      "source": [
        "!rm NewsAggregatorDataset.zip\n",
        "!wget --no-check-certificate -q \"https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\"\n",
        "!unzip -n NewsAggregatorDataset.zip\n",
        "!rm -rf __MACOSX\n",
        "!pip install stemming\n",
        "!pip install spacy\n",
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'NewsAggregatorDataset.zip': No such file or directory\n",
            "Archive:  NewsAggregatorDataset.zip\n",
            "  inflating: 2pageSessions.csv       \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "  inflating: newsCorpora.csv         \n",
            "  inflating: __MACOSX/._newsCorpora.csv  \n",
            "  inflating: readme.txt              \n",
            "  inflating: __MACOSX/._readme.txt   \n",
            "Collecting stemming\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/eb/fd53fb51b83a4e3b8e98cfec2fa9e4b99401fce5177ec346e4a5c61df71e/stemming-1.0.1.tar.gz\n",
            "Building wheels for collected packages: stemming\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-cp36-none-any.whl size=11139 sha256=d22a6ea39892f18e02f3a8b2bb12ca39b48e4437a1707782d142d9d5a76c2d10\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/05/2e/2ddeb64d4464b854b48323f9676528c17560da7d153db7b0e2\n",
            "Successfully built stemming\n",
            "Installing collected packages: stemming\n",
            "Successfully installed stemming-1.0.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.3.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKrhf9vn38KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import gensim\n",
        "import numpy as np\n",
        "import re\n",
        "from stemming.porter2 import stem\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfQMX-wN36Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Article:\n",
        "  def __init__(self,ID,TITLE,CATEGORY):\n",
        "    self.id=ID\n",
        "    self.title=TITLE\n",
        "    self.category=CATEGORY\n",
        "    self.feature_unigram=[]\n",
        "  def get_title(self):\n",
        "    return self.title\n",
        "  def set_unigram(self,library,nlp):\n",
        "        word_dic={}\n",
        "        for word in nlp.make_doc(self.title):\n",
        "            tmp=stem(word.lemma_.lower())\n",
        "            word_dic.setdefault(tmp,0)\n",
        "            word_dic[tmp]+=1\n",
        "        for word in library:\n",
        "            if word in word_dic.keys():\n",
        "                self.feature_unigram.append(word_dic[word])\n",
        "            else:\n",
        "                self.feature_unigram.append(0)\n",
        "\n",
        "drive_colab=drive_root_dir+\"/Colab Notebooks\"\n",
        "drive_ch9=drive_root_dir+\"/Colab Notebooks/ch9\"\n",
        "test_articles=[]\n",
        "train_articles=[]\n",
        "valid_articles=[]\n",
        "with open(drive_colab+\"/test.txt\") as test, open(drive_colab+\"/train.txt\") as train, open(drive_colab+\"/valid.txt\") as valid:\n",
        "  for line in test.readlines():\n",
        "    elms=line.split('\\t')\n",
        "    article=Article(elms[0],elms[1],elms[4])\n",
        "    test_articles.append(article)\n",
        "  for line in train.readlines():\n",
        "    elms=line.split('\\t')\n",
        "    article=Article(elms[0],elms[1],elms[4])\n",
        "    train_articles.append(article)\n",
        "  for line in valid.readlines():\n",
        "    elms=line.split('\\t')\n",
        "    article=Article(elms[0],elms[1],elms[4])\n",
        "    valid_articles.append(article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsRa5M_S45bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp=spacy.load('en')\n",
        "def create_text_word_dic(articles,nlp):\n",
        "    word_dic={}\n",
        "    for article in articles:\n",
        "        for word in nlp.make_doc(article.get_title()):\n",
        "            tmp=stem(word.lemma_.lower())\n",
        "            word_dic.setdefault(tmp,0)\n",
        "            word_dic[tmp]+=1\n",
        "    word_dic2={}\n",
        "    for key,value in word_dic.items():\n",
        "        if 2<value:\n",
        "            word_dic2.setdefault(key,value)\n",
        "    return word_dic2\n",
        "library=[]\n",
        "for word in create_text_word_dic(train_articles,nlp):\n",
        "    library.append(word)\n",
        "for article in train_articles:\n",
        "    article.set_unigram(library,nlp)\n",
        "for article in valid_articles:\n",
        "    article.set_unigram(library,nlp)\n",
        "for article in test_articles:\n",
        "    article.set_unigram(library,nlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPZGk3KVAbyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_articles.pickle\",'wb') as f:\n",
        "  pickle.dump(train_articles,f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_articles.pickle\",'wb') as f:\n",
        "  pickle.dump(test_articles,f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_articles.pickle\",'wb') as f:\n",
        "  pickle.dump(valid_articles,f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/library.pickle\",'wb') as f:\n",
        "  pickle.dump(library,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWa8xnVm9vRn",
        "colab_type": "text"
      },
      "source": [
        "## 本文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDkQWCBuaGGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Article:\n",
        "  def __init__(self,ID,TITLE,CATEGORY):\n",
        "    self.id=ID\n",
        "    self.title=TITLE\n",
        "    self.category=CATEGORY\n",
        "    self.feature_unigram=[]\n",
        "  def get_title(self):\n",
        "    return self.title\n",
        "  def set_unigram(self,library,nlp):\n",
        "        word_dic={}\n",
        "        for word in nlp.make_doc(self.title):\n",
        "            tmp=stem(word.lemma_.lower())\n",
        "            word_dic.setdefault(tmp,0)\n",
        "            word_dic[tmp]+=1\n",
        "        for word in library:\n",
        "            if word in word_dic.keys():\n",
        "                self.feature_unigram.append(word_dic[word])\n",
        "            else:\n",
        "                self.feature_unigram.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qcX9g0V92dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_articles.pickle\",'rb') as f:\n",
        "  train_articles = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_articles.pickle\",'rb') as f:\n",
        "  test_articles = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_articles.pickle\",'rb') as f:\n",
        "  valid_articles = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/library.pickle\",'rb') as f:\n",
        "  library = pickle.load(f)\n",
        "nlp=spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3a5NLS5-pfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frequency = [0] * len(library)\n",
        "frequency = np.array(frequency)\n",
        "\n",
        "for article in train_articles:\n",
        "  frequency = frequency + np.array(article.feature_unigram)\n",
        "\n",
        "word_frequency={}\n",
        "for word,count in zip(library,frequency):\n",
        "  word_frequency.setdefault(word,count)\n",
        "\n",
        "word_frequency = sorted(word_frequency.items(),reverse=True)\n",
        "word_ID = {}\n",
        "ID=1\n",
        "for word,frequency in word_frequency:\n",
        "  if frequency > 1:\n",
        "    word_ID.setdefault(word,ID)\n",
        "    ID += 1\n",
        "  else :\n",
        "    word_ID.setdefault(word,0)\n",
        "\n",
        "def sentence_ID(sentence, word_ID, nlp):\n",
        "  word_num=[]\n",
        "  for word in nlp.make_doc(sentence):\n",
        "    tmp=stem(word.lemma_.lower())\n",
        "    if tmp in word_ID.keys():\n",
        "      word_num.append(word_ID[tmp])\n",
        "    else:\n",
        "      word_num.append(0)\n",
        "  return word_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kisLlUEw9zg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edd093a1-78d0-4200-b9b9-5e7f98127c52"
      },
      "source": [
        "sentence_ID(\"I am Shimokawa.\",word_ID,nlp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2570, 4191, 0, 4790]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jF0W3bYYLMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/word_ID.pickle\",'wb') as f:\n",
        "  pickle.dump(word_ID,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXYMHB2j0RWp",
        "colab_type": "text"
      },
      "source": [
        "# 問題81"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rs18Y9paUjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp=spacy.load('en')\n",
        "def sentence_ID(sentence, word_ID, nlp):\n",
        "  word_num=[]\n",
        "  for word in nlp.make_doc(sentence):\n",
        "    tmp=stem(word.lemma_.lower())\n",
        "    if tmp in word_ID.keys():\n",
        "      word_num.append(word_ID[tmp])\n",
        "    else:\n",
        "      word_num.append(0)\n",
        "  return word_num\n",
        "class Article:\n",
        "  def __init__(self,ID,TITLE,CATEGORY):\n",
        "    self.id=ID\n",
        "    self.title=TITLE\n",
        "    self.category=CATEGORY\n",
        "    self.feature_unigram=[]\n",
        "  def get_title(self):\n",
        "    return self.title\n",
        "  def set_unigram(self,library,nlp):\n",
        "        word_dic={}\n",
        "        for word in nlp.make_doc(self.title):\n",
        "            tmp=stem(word.lemma_.lower())\n",
        "            word_dic.setdefault(tmp,0)\n",
        "            word_dic[tmp]+=1\n",
        "        for word in library:\n",
        "            if word in word_dic.keys():\n",
        "                self.feature_unigram.append(word_dic[word])\n",
        "            else:\n",
        "                self.feature_unigram.append(0)\n",
        "import pickle\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_articles.pickle\",'rb') as f:\n",
        "  train_articles = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_articles.pickle\",'rb') as f:\n",
        "  test_articles = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_articles.pickle\",'rb') as f:\n",
        "  valid_articles = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/library.pickle\",'rb') as f:\n",
        "  library = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/word_ID.pickle\",'rb') as f:\n",
        "  word_ID = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgubO0OaamNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_word_ids=[]\n",
        "for article in train_articles:\n",
        "  ids = sentence_ID(article.title,word_ID,nlp)\n",
        "  train_word_ids.append(ids)\n",
        "test_word_ids=[]\n",
        "for article in test_articles:\n",
        "  ids = sentence_ID(article.title,word_ID,nlp)\n",
        "  test_word_ids.append(ids)\n",
        "valid_word_ids=[]\n",
        "for article in valid_articles:\n",
        "  ids = sentence_ID(article.title,word_ID,nlp)\n",
        "  valid_word_ids.append(ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SVZFPnpeSnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_word_ids.pickle\",'wb') as f:\n",
        "  pickle.dump(train_word_ids,f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_word_ids.pickle\",'wb') as f:\n",
        "  pickle.dump(test_word_ids,f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_word_ids.pickle\",'wb') as f:\n",
        "  pickle.dump(valid_word_ids,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTqxPKVEejRt",
        "colab_type": "text"
      },
      "source": [
        "## ここまで、id列作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6v95SxPgKG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cate={'b':0,'t':1,'e':2,'m':3}\n",
        "train_categories=[]\n",
        "for article in train_articles:\n",
        "  train_categories.append(cate[article.category])\n",
        "test_categories=[]\n",
        "for article in test_articles:\n",
        "  test_categories.append(cate[article.category])\n",
        "valid_categories=[]\n",
        "for article in valid_articles:\n",
        "  valid_categories.append(cate[article.category])\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_categories.pickle\",'wb') as f:\n",
        "  pickle.dump(train_categories,f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_categories.pickle\",'wb') as f:\n",
        "  pickle.dump(test_categories,f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_categories.pickle\",'wb') as f:\n",
        "  pickle.dump(valid_categories,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KydwtwMyg-e7",
        "colab_type": "text"
      },
      "source": [
        "## ここまでカテゴリーリスト作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pakgr6ZUeyDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "f677cd0c-ee3a-4a3d-8bf5-092fe3491489"
      },
      "source": [
        "!pip install stemming\n",
        "!pip install spacy\n",
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stemming\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/eb/fd53fb51b83a4e3b8e98cfec2fa9e4b99401fce5177ec346e4a5c61df71e/stemming-1.0.1.tar.gz\n",
            "Building wheels for collected packages: stemming\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-cp36-none-any.whl size=11139 sha256=9be790db02c9a49d8ad97d0e765939e57a6d744f79aadbbdf08ea417264bd102\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/05/2e/2ddeb64d4464b854b48323f9676528c17560da7d153db7b0e2\n",
            "Successfully built stemming\n",
            "Installing collected packages: stemming\n",
            "Successfully installed stemming-1.0.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.3.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFhfRzxMem7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c4e72245-fc5c-4c13-bce7-affcfc1313ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_root_dir=\"./drive/My Drive\"\n",
        "import spacy\n",
        "import gensim\n",
        "import numpy as np\n",
        "import re\n",
        "from stemming.porter2 import stem\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWqfqZIiexmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "nlp=spacy.load('en')\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_word_ids.pickle\",'rb') as f:\n",
        "  train_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_word_ids.pickle\",'rb') as f:\n",
        "  test_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_word_ids.pickle\",'rb') as f:\n",
        "  valid_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/word_ID.pickle\",'rb') as f:\n",
        "  word_ID = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_categories.pickle\",'rb') as f:\n",
        "  train_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_categories.pickle\",'rb') as f:\n",
        "  test_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_categories.pickle\",'rb') as f:\n",
        "  valid_categories = pickle.load(f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UejjQwtO0TtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "9e2656a3-f260-4ef0-9c50-fba5677ce7c7"
      },
      "source": [
        " !pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 23kB/s \n",
            "\u001b[?25hCollecting torchvision===0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision===0.5.0) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.5.0) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision===0.5.0) (1.12.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDyjaXQc5JxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKVi-Ail58cT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self,x_size, e_size, h_size, o_size):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(x_size, e_size)\n",
        "    self.rnn = nn.LSTM(e_size, h_size)\n",
        "    self.out = nn.Linear(h_size, o_size)\n",
        "\n",
        "  def predict(self, x, state = None):\n",
        "    x = self.embed(x.to(torch.int64))\n",
        "    x, (h, c) = self.rnn(x, state)\n",
        "    h = F.softmax(self.out(h.squeeze(0)[len(h)-1]))\n",
        "    return h\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.predict(x)\n",
        "\n",
        "model = Model(len(word_ID)+1,300,50,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7s2hSv0uXwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def from_ids_to_onehot_tensor(ids, word_ID):\n",
        "  tensor_words = torch.zeros([len(ids), len(word_ID)+1])\n",
        "  for i,word_id in enumerate(ids):\n",
        "    tensor_words[i] [word_id]= 1 \n",
        "  return tensor_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TABQ92gWv9a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_tensor_tmp = from_ids_to_onehot_tensor(train_word_ids[0], word_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9xUAwrCxFZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "b4c07015-5577-4990-fb60-b266277484e0"
      },
      "source": [
        "print(model.predict(id_tensor_tmp))\n",
        "print(train_categories[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3205, 0.1854, 0.2700, 0.2241], grad_fn=<SoftmaxBackward>)\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGIhFcr75xWR",
        "colab_type": "text"
      },
      "source": [
        "# 問題82"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naepaoFj1j8y",
        "colab_type": "text"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvv_H3VGF8YK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "80c3817e-b0b0-452f-8911-623dc32bf32a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_root_dir=\"./drive/My Drive\"\n",
        "import gensim\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8rm3KiFF-XW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_word_ids.pickle\",'rb') as f:\n",
        "  train_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_word_ids.pickle\",'rb') as f:\n",
        "  test_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_word_ids.pickle\",'rb') as f:\n",
        "  valid_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/word_ID.pickle\",'rb') as f:\n",
        "  word_ID = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_categories.pickle\",'rb') as f:\n",
        "  train_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_categories.pickle\",'rb') as f:\n",
        "  test_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_categories.pickle\",'rb') as f:\n",
        "  valid_categories = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS8lUWFXGECF",
        "colab_type": "text"
      },
      "source": [
        "## 本文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weSW1qXIGHwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.utils.rnn as rnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bpB30BGGJ1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, i_size, e_size, h_size, o_size):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(i_size, e_size)\n",
        "    self.rnn = nn.RNN(e_size, h_size, num_layers=1, batch_first=True)\n",
        "    self.fc1 = nn.Linear(h_size, o_size)\n",
        "\n",
        "    nn.init.normal_(self.fc1.weight, -0.1, 0.1)\n",
        "  \n",
        "  def forward(self, ids):\n",
        "    device = self.parameters().__next__().device\n",
        "    hidden = None\n",
        "    x = self.embed(ids.to(torch.int64).to(device))\n",
        "    x, h = self.rnn(x, hidden)\n",
        "    output = F.softmax(self.fc1(h.squeeze()))\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Myowe6ZeMFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dummy_dataloader():\n",
        "  def __init__(self, data, category, batch_size):\n",
        "    self.data = data\n",
        "    self.category = category\n",
        "    self.batch_size = batch_size\n",
        "    self.count=0\n",
        "  def get(self):\n",
        "    datas=[]\n",
        "    categories =[]\n",
        "    while self.count*self.batch_size <= len(self.data) :\n",
        "      if (self.count+1)*self.batch_size > len(self.data):\n",
        "        output_data = self.data[self.count*self.batch_size:]\n",
        "        output_category = self.category[self.count*self.batch_size:]\n",
        "        datas.append(output_data)\n",
        "        categories.append(output_category)\n",
        "        self.count = 0\n",
        "        break\n",
        "      else:\n",
        "        output_data = self.data[self.count*self.batch_size:(self.count+1)*self.batch_size]\n",
        "        output_category = self.category[self.count*self.batch_size:(self.count+1)*self.batch_size]\n",
        "        datas.append(output_data)\n",
        "        categories.append(output_category)\n",
        "        self.count +=1\n",
        "    return zip(datas, categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k7WTV9FgbP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def item_sorted(datas, categories):\n",
        "  dic = []\n",
        "  for data, category in zip(datas, categories):\n",
        "    dic.append([category, data])\n",
        "  dic=sorted(dic, key=lambda x:len(x[1]), reverse=True)\n",
        "  data_sorted=[]\n",
        "  cate_sorted=[]\n",
        "  for item in dic:\n",
        "    data_sorted.append(item[1])\n",
        "    cate_sorted.append(item[0])\n",
        "  return data_sorted, cate_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfjWA47AtHHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def match_padding(ids):\n",
        "  max_length = max([len(id) for id in ids])\n",
        "  result = torch.zeros(len(ids), max_length)\n",
        "  for i in range(len(ids)):\n",
        "    for j in range(len(ids[i])):\n",
        "      result[i][j] = ids[i][j]\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js3h2o0HtwwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def all_model(datas, categories, model):\n",
        "  preds=[]\n",
        "  \n",
        "  sorted_data, sorted_cate=item_sorted(datas, categories)\n",
        "  dataloader = Dummy_dataloader(sorted_data, sorted_cate, batch_size)\n",
        "  for data, category in dataloader.get():\n",
        "    p_data = match_padding(data)\n",
        "    for i in model(p_data):  #実質o(n) nはサンプル数\n",
        "      preds.append(i.detach().numpy().tolist())\n",
        "  return preds, sorted_cate\n",
        "\n",
        "def calc_accuracy(datas, categories, model):\n",
        "  preds,cate =all_model(datas, categories, model)\n",
        "  return accuracy_score(cate, [np.argmax(np.array(pred)) for pred in preds])\n",
        "\n",
        "def calc_loss(datas, categories, model):\n",
        "  CEL = nn.CrossEntropyLoss()\n",
        "  preds,cate =all_model(datas, categories, model)\n",
        "  loss = CEL(torch.tensor(preds), torch.tensor(cate))\n",
        "  return loss.item()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogmPTCbiZIbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_sorted_data, train_sorted_cate=item_sorted(train_word_ids, train_categories)\n",
        "train_dataloader = Dummy_dataloader(train_sorted_data, train_sorted_cate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv2Nnj_LXxi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e8741b9-aa40-4f34-971a-afaf47eccef7"
      },
      "source": [
        "model = Model(len(word_ID)+1, 300, 50, 4)\n",
        "CEL = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(20):\n",
        "  for datas, categories in train_dataloader.get():\n",
        "    ids = Variable(match_padding(datas))\n",
        "    cate = Variable(torch.tensor(categories))\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    pred = model(ids)\n",
        "    loss = CEL(pred, cate)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"epoch:{}\".format(epoch))\n",
        "  print(\"\\ttrain\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(train_word_ids, train_categories, model),\n",
        "                                        calc_accuracy(train_word_ids, train_categories, model)))\n",
        "  print(\"\\ttest\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(test_word_ids, test_categories, model),\n",
        "                                        calc_accuracy(test_word_ids, test_categories, model)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "\ttrain\n",
            "\t\tloss1.1491923332214355,acccuracy0.5998128217126814\n",
            "\ttest\n",
            "\t\tloss1.1675426959991455,acccuracy0.5850187265917604\n",
            "epoch:1\n",
            "\ttrain\n",
            "\t\tloss1.0900119543075562,acccuracy0.6541881141787552\n",
            "\ttest\n",
            "\t\tloss1.1138664484024048,acccuracy0.6292134831460674\n",
            "epoch:2\n",
            "\ttrain\n",
            "\t\tloss1.0238181352615356,acccuracy0.7222274216190921\n",
            "\ttest\n",
            "\t\tloss1.0448280572891235,acccuracy0.6928838951310862\n",
            "epoch:3\n",
            "\ttrain\n",
            "\t\tloss0.991697371006012,acccuracy0.7520823584464202\n",
            "\ttest\n",
            "\t\tloss1.0041372776031494,acccuracy0.7415730337078652\n",
            "epoch:4\n",
            "\ttrain\n",
            "\t\tloss0.9840864539146423,acccuracy0.7595694899391671\n",
            "\ttest\n",
            "\t\tloss1.000840425491333,acccuracy0.7460674157303371\n",
            "epoch:5\n",
            "\ttrain\n",
            "\t\tloss0.9720903038978577,acccuracy0.77042583060365\n",
            "\ttest\n",
            "\t\tloss0.9926196336746216,acccuracy0.7475655430711611\n",
            "epoch:6\n",
            "\ttrain\n",
            "\t\tloss0.9554251432418823,acccuracy0.7883013570425831\n",
            "\ttest\n",
            "\t\tloss0.973486065864563,acccuracy0.7662921348314606\n",
            "epoch:7\n",
            "\ttrain\n",
            "\t\tloss0.9458128213882446,acccuracy0.797473093121198\n",
            "\ttest\n",
            "\t\tloss0.9697364568710327,acccuracy0.7700374531835206\n",
            "epoch:8\n",
            "\ttrain\n",
            "\t\tloss0.9392478466033936,acccuracy0.8038371548900327\n",
            "\ttest\n",
            "\t\tloss0.9630786180496216,acccuracy0.7782771535580524\n",
            "epoch:9\n",
            "\ttrain\n",
            "\t\tloss0.9374380111694336,acccuracy0.8059897051941974\n",
            "\ttest\n",
            "\t\tloss0.9630560278892517,acccuracy0.7782771535580524\n",
            "epoch:10\n",
            "\ttrain\n",
            "\t\tloss0.9307047128677368,acccuracy0.8121665886757136\n",
            "\ttest\n",
            "\t\tloss0.9572113752365112,acccuracy0.7835205992509363\n",
            "epoch:11\n",
            "\ttrain\n",
            "\t\tloss0.9251965284347534,acccuracy0.8180627047262518\n",
            "\ttest\n",
            "\t\tloss0.9563453793525696,acccuracy0.7827715355805244\n",
            "epoch:12\n",
            "\ttrain\n",
            "\t\tloss0.9237318634986877,acccuracy0.8198408984557791\n",
            "\ttest\n",
            "\t\tloss0.9554396867752075,acccuracy0.7850187265917603\n",
            "epoch:13\n",
            "\ttrain\n",
            "\t\tloss0.9153754115104675,acccuracy0.8269536733738886\n",
            "\ttest\n",
            "\t\tloss0.9548685550689697,acccuracy0.7857677902621722\n",
            "epoch:14\n",
            "\ttrain\n",
            "\t\tloss0.906467080116272,acccuracy0.8378100140383715\n",
            "\ttest\n",
            "\t\tloss0.9492133259773254,acccuracy0.7895131086142322\n",
            "epoch:15\n",
            "\ttrain\n",
            "\t\tloss0.9056151509284973,acccuracy0.8399625643425362\n",
            "\ttest\n",
            "\t\tloss0.9496070742607117,acccuracy0.7917602996254681\n",
            "epoch:16\n",
            "\ttrain\n",
            "\t\tloss0.8997352123260498,acccuracy0.8452971455311183\n",
            "\ttest\n",
            "\t\tloss0.9446125626564026,acccuracy0.7947565543071161\n",
            "epoch:17\n",
            "\ttrain\n",
            "\t\tloss0.8939303159713745,acccuracy0.8523163313055686\n",
            "\ttest\n",
            "\t\tloss0.9431883096694946,acccuracy0.7940074906367042\n",
            "epoch:18\n",
            "\ttrain\n",
            "\t\tloss0.8937692046165466,acccuracy0.8508189050070192\n",
            "\ttest\n",
            "\t\tloss0.9411883354187012,acccuracy0.8014981273408239\n",
            "epoch:19\n",
            "\ttrain\n",
            "\t\tloss0.8879671096801758,acccuracy0.8581188582124474\n",
            "\ttest\n",
            "\t\tloss0.9437305927276611,acccuracy0.799250936329588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMvxe9_QjPsz",
        "colab_type": "text"
      },
      "source": [
        "# 問題83"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8I_g7ECjUJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_sorted_data, train_sorted_cate=item_sorted(train_word_ids, train_categories)\n",
        "train_dataloader = Dummy_dataloader(train_sorted_data, train_sorted_cate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCpkFkWWjVSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_gpu(e):\n",
        "    if torch.cuda.is_available():\n",
        "        return e.cuda()\n",
        "    return e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djbV-ZkGjkn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def all_model(datas, categories, model, gpu = False):\n",
        "  preds=[]\n",
        "  \n",
        "  sorted_data, sorted_cate=item_sorted(datas, categories)\n",
        "  dataloader = Dummy_dataloader(sorted_data, sorted_cate, batch_size)\n",
        "  for data, category in dataloader.get():\n",
        "    p_data = match_padding(data)\n",
        "    if gpu:\n",
        "      p_data = try_gpu(p_data)\n",
        "    for i in model(p_data):  #実質o(n) nはサンプル数\n",
        "      preds.append(i.cpu().detach().numpy().tolist())\n",
        "  return preds, sorted_cate\n",
        "\n",
        "def calc_accuracy(datas, categories, model, gpu):\n",
        "  preds,cate =all_model(datas, categories, model)\n",
        "  return accuracy_score(cate, [np.argmax(np.array(pred)) for pred in preds])\n",
        "\n",
        "def calc_loss(datas, categories, model, gpu = False):\n",
        "  CEL = nn.CrossEntropyLoss()\n",
        "  preds,cate =all_model(datas, categories, model, gpu)\n",
        "  loss = CEL(torch.tensor(preds), torch.tensor(cate))\n",
        "  return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9avc1LqjWrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b699a882-f8d2-4e2c-f8c2-6dd62c2bf418"
      },
      "source": [
        "model = try_gpu(Model(len(word_ID)+1, 300, 50, 4))\n",
        "CEL = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "for epoch in range(20):\n",
        "  for datas, categories in train_dataloader.get():\n",
        "    ids = try_gpu(Variable(match_padding(datas)))\n",
        "    cate = try_gpu(Variable(torch.tensor(categories)))\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    pred = model(ids)\n",
        "\n",
        "    loss = CEL(pred, cate)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"epoch:{}\".format(epoch))\n",
        "  print(\"\\ttrain\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(train_word_ids, train_categories, model, gpu=True),\n",
        "                                        calc_accuracy(train_word_ids, train_categories, model, gpu=True)))\n",
        "  print(\"\\ttest\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(test_word_ids, test_categories, model, gpu=True),\n",
        "                                        calc_accuracy(test_word_ids, test_categories, model, gpu=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "\ttrain\n",
            "\t\tloss1.210397481918335,acccuracy0.554796443612541\n",
            "\ttest\n",
            "\t\tloss1.2257423400878906,acccuracy0.5295880149812734\n",
            "epoch:1\n",
            "\ttrain\n",
            "\t\tloss1.1542720794677734,acccuracy0.5973795039775386\n",
            "\ttest\n",
            "\t\tloss1.1747606992721558,acccuracy0.5775280898876405\n",
            "epoch:2\n",
            "\ttrain\n",
            "\t\tloss1.121736764907837,acccuracy0.6256434253626579\n",
            "\ttest\n",
            "\t\tloss1.1454110145568848,acccuracy0.5970037453183521\n",
            "epoch:3\n",
            "\ttrain\n",
            "\t\tloss1.0822229385375977,acccuracy0.6665418811417876\n",
            "\ttest\n",
            "\t\tloss1.10958993434906,acccuracy0.6299625468164795\n",
            "epoch:4\n",
            "\ttrain\n",
            "\t\tloss1.0480899810791016,acccuracy0.6962096396817969\n",
            "\ttest\n",
            "\t\tloss1.0695960521697998,acccuracy0.6681647940074906\n",
            "epoch:5\n",
            "\ttrain\n",
            "\t\tloss1.0203295946121216,acccuracy0.7226953673373888\n",
            "\ttest\n",
            "\t\tloss1.038426399230957,acccuracy0.7056179775280899\n",
            "epoch:6\n",
            "\ttrain\n",
            "\t\tloss1.008458137512207,acccuracy0.7354234908750585\n",
            "\ttest\n",
            "\t\tloss1.0257203578948975,acccuracy0.7191011235955056\n",
            "epoch:7\n",
            "\ttrain\n",
            "\t\tloss0.9830543994903564,acccuracy0.7604117922321011\n",
            "\ttest\n",
            "\t\tloss0.9979327321052551,acccuracy0.7453183520599251\n",
            "epoch:8\n",
            "\ttrain\n",
            "\t\tloss0.9717767238616943,acccuracy0.7717360786148807\n",
            "\ttest\n",
            "\t\tloss0.9854636788368225,acccuracy0.7573033707865169\n",
            "epoch:9\n",
            "\ttrain\n",
            "\t\tloss0.9631651639938354,acccuracy0.7806270472625175\n",
            "\ttest\n",
            "\t\tloss0.9808565378189087,acccuracy0.7632958801498128\n",
            "epoch:10\n",
            "\ttrain\n",
            "\t\tloss0.954579770565033,acccuracy0.7881141787552643\n",
            "\ttest\n",
            "\t\tloss0.9678124189376831,acccuracy0.7737827715355805\n",
            "epoch:11\n",
            "\ttrain\n",
            "\t\tloss0.9518188834190369,acccuracy0.7899859616284511\n",
            "\ttest\n",
            "\t\tloss0.9690918922424316,acccuracy0.7715355805243446\n",
            "epoch:12\n",
            "\ttrain\n",
            "\t\tloss0.948854923248291,acccuracy0.7933551708001871\n",
            "\ttest\n",
            "\t\tloss0.9676539301872253,acccuracy0.7790262172284644\n",
            "epoch:13\n",
            "\ttrain\n",
            "\t\tloss0.9421527981758118,acccuracy0.7998128217126813\n",
            "\ttest\n",
            "\t\tloss0.9568042755126953,acccuracy0.7872659176029962\n",
            "epoch:14\n",
            "\ttrain\n",
            "\t\tloss0.9380301237106323,acccuracy0.8038371548900327\n",
            "\ttest\n",
            "\t\tloss0.955324649810791,acccuracy0.7865168539325843\n",
            "epoch:15\n",
            "\ttrain\n",
            "\t\tloss0.9359073638916016,acccuracy0.8072999532054281\n",
            "\ttest\n",
            "\t\tloss0.957560658454895,acccuracy0.7857677902621722\n",
            "epoch:16\n",
            "\ttrain\n",
            "\t\tloss0.9329689741134644,acccuracy0.8086102012166588\n",
            "\ttest\n",
            "\t\tloss0.9572831392288208,acccuracy0.7827715355805244\n",
            "epoch:17\n",
            "\ttrain\n",
            "\t\tloss0.9267828464508057,acccuracy0.8155357978474497\n",
            "\ttest\n",
            "\t\tloss0.9505016207695007,acccuracy0.7932584269662921\n",
            "epoch:18\n",
            "\ttrain\n",
            "\t\tloss0.9233733415603638,acccuracy0.8205896116050538\n",
            "\ttest\n",
            "\t\tloss0.9492537975311279,acccuracy0.7932584269662921\n",
            "epoch:19\n",
            "\ttrain\n",
            "\t\tloss0.9204326868057251,acccuracy0.8236780533458119\n",
            "\ttest\n",
            "\t\tloss0.949381947517395,acccuracy0.7955056179775281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXa-HhskmS4a",
        "colab_type": "text"
      },
      "source": [
        "# 問題84"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK3zxDf_mX8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "ade738db-73c2-427e-96f9-31c173f795ee"
      },
      "source": [
        "!rm GoogleNews-vectors-negative300.bin.gz GoogleNews-vectors-negative300.bin\n",
        "!wget -q https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
        "!gunzip -n GoogleNews-vectors-negative300.bin.gz\n",
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'GoogleNews-vectors-negative300.bin.gz': No such file or directory\n",
            "rm: cannot remove 'GoogleNews-vectors-negative300.bin': No such file or directory\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.9)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubu4-v-amml6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ddb0cd8e-8709-4cea-ca8c-165536889934"
      },
      "source": [
        "import gensim\n",
        "gen = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoKPu5KLneFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pickle\n",
        "weight = []\n",
        "for word in word_ID.keys():\n",
        "  if word in gen:\n",
        "    weight.append([word_ID[word], gen[word]])\n",
        "del gen\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/weight.pickle\",'wb') as f:\n",
        "  pickle.dump(weight,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwBYXQCAoVTO",
        "colab_type": "text"
      },
      "source": [
        "## 本文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4S79s_xvIvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_word_ids.pickle\",'rb') as f:\n",
        "  train_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_word_ids.pickle\",'rb') as f:\n",
        "  test_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_word_ids.pickle\",'rb') as f:\n",
        "  valid_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/word_ID.pickle\",'rb') as f:\n",
        "  word_ID = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_categories.pickle\",'rb') as f:\n",
        "  train_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_categories.pickle\",'rb') as f:\n",
        "  test_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_categories.pickle\",'rb') as f:\n",
        "  valid_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/weight.pickle\",'rb') as f:\n",
        "  weight = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RO25qjnoXRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, i_size, e_size, h_size, o_size, embed_weight, gpu=False):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(i_size, e_size)\n",
        "    self.rnn = nn.RNN(e_size, h_size, num_layers=1, batch_first=True)\n",
        "    self.fc1 = nn.Linear(h_size, o_size)\n",
        "\n",
        "    nn.init.normal_(self.fc1.weight, -0.1, 0.1)\n",
        "    for word_num , weight in embed_weight:\n",
        "      self.embed.weight.data[word_num] = torch.FloatTensor(weight)\n",
        "    if gpu:\n",
        "      try_gpu(self.embed)\n",
        "\n",
        "  def forward(self, ids):\n",
        "    device = self.parameters().__next__().device\n",
        "    hidden = None\n",
        "    x = self.embed(ids.to(torch.int64).to(device))\n",
        "    x, h = self.rnn(x, hidden)\n",
        "    output = F.softmax(self.fc1(h.squeeze()))\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKfEWjFiui2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_sorted_data, train_sorted_cate=item_sorted(train_word_ids, train_categories)\n",
        "train_dataloader = Dummy_dataloader(train_sorted_data, train_sorted_cate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv_kdV7avCz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93aa1e04-8a3d-4337-df62-9a0fcaa16075"
      },
      "source": [
        "model = try_gpu(Model(len(word_ID)+1, 300, 50, 4, weight, True))\n",
        "CEL = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "for epoch in range(20):\n",
        "  for datas, categories in train_dataloader.get():\n",
        "    ids = try_gpu(Variable(match_padding(datas)))\n",
        "    cate = try_gpu(Variable(torch.tensor(categories)))\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    pred = model(ids)\n",
        "\n",
        "    loss = CEL(pred, cate)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"epoch:{}\".format(epoch))\n",
        "  print(\"\\ttrain\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(train_word_ids, train_categories, model, gpu=True),\n",
        "                                        calc_accuracy(train_word_ids, train_categories, model, gpu=True)))\n",
        "  print(\"\\ttest\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(test_word_ids, test_categories, model, gpu=True),\n",
        "                                        calc_accuracy(test_word_ids, test_categories, model, gpu=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "\ttrain\n",
            "\t\tloss1.1777937412261963,acccuracy0.557604117922321\n",
            "\ttest\n",
            "\t\tloss1.1908483505249023,acccuracy0.5423220973782772\n",
            "epoch:1\n",
            "\ttrain\n",
            "\t\tloss1.085305094718933,acccuracy0.6643893308376229\n",
            "\ttest\n",
            "\t\tloss1.1163214445114136,acccuracy0.6202247191011236\n",
            "epoch:2\n",
            "\ttrain\n",
            "\t\tloss1.0249745845794678,acccuracy0.7171736078614881\n",
            "\ttest\n",
            "\t\tloss1.0378226041793823,acccuracy0.701123595505618\n",
            "epoch:3\n",
            "\ttrain\n",
            "\t\tloss0.9975230693817139,acccuracy0.7460926532522227\n",
            "\ttest\n",
            "\t\tloss1.0055290460586548,acccuracy0.7340823970037453\n",
            "epoch:4\n",
            "\ttrain\n",
            "\t\tloss0.9844498634338379,acccuracy0.759288722508189\n",
            "\ttest\n",
            "\t\tloss0.989669919013977,acccuracy0.750561797752809\n",
            "epoch:5\n",
            "\ttrain\n",
            "\t\tloss0.9799051880836487,acccuracy0.7635938231165185\n",
            "\ttest\n",
            "\t\tloss0.9807724952697754,acccuracy0.7647940074906368\n",
            "epoch:6\n",
            "\ttrain\n",
            "\t\tloss0.9742769598960876,acccuracy0.7682732802994853\n",
            "\ttest\n",
            "\t\tloss0.9755774140357971,acccuracy0.7685393258426966\n",
            "epoch:7\n",
            "\ttrain\n",
            "\t\tloss0.968932032585144,acccuracy0.7744501637810014\n",
            "\ttest\n",
            "\t\tloss0.9687515497207642,acccuracy0.7737827715355805\n",
            "epoch:8\n",
            "\ttrain\n",
            "\t\tloss0.9693823456764221,acccuracy0.774075807206364\n",
            "\ttest\n",
            "\t\tloss0.9717893004417419,acccuracy0.7715355805243446\n",
            "epoch:9\n",
            "\ttrain\n",
            "\t\tloss0.9644185900688171,acccuracy0.7788488535329902\n",
            "\ttest\n",
            "\t\tloss0.9668066501617432,acccuracy0.7737827715355805\n",
            "epoch:10\n",
            "\ttrain\n",
            "\t\tloss0.9617497324943542,acccuracy0.7817501169864296\n",
            "\ttest\n",
            "\t\tloss0.9666968584060669,acccuracy0.7760299625468164\n",
            "epoch:11\n",
            "\ttrain\n",
            "\t\tloss0.9590380191802979,acccuracy0.784089845577913\n",
            "\ttest\n",
            "\t\tloss0.9621803164482117,acccuracy0.7805243445692884\n",
            "epoch:12\n",
            "\ttrain\n",
            "\t\tloss0.9593577980995178,acccuracy0.7837154890032756\n",
            "\ttest\n",
            "\t\tloss0.9621326923370361,acccuracy0.7812734082397004\n",
            "epoch:13\n",
            "\ttrain\n",
            "\t\tloss0.9576894640922546,acccuracy0.7854000935891436\n",
            "\ttest\n",
            "\t\tloss0.9632096290588379,acccuracy0.7790262172284644\n",
            "epoch:14\n",
            "\ttrain\n",
            "\t\tloss0.9603792428970337,acccuracy0.7832475432849789\n",
            "\ttest\n",
            "\t\tloss0.9688205122947693,acccuracy0.7722846441947565\n",
            "epoch:15\n",
            "\ttrain\n",
            "\t\tloss0.9548054933547974,acccuracy0.788582124473561\n",
            "\ttest\n",
            "\t\tloss0.9608637094497681,acccuracy0.7805243445692884\n",
            "epoch:16\n",
            "\ttrain\n",
            "\t\tloss0.9519670009613037,acccuracy0.7909218530650445\n",
            "\ttest\n",
            "\t\tloss0.9604317545890808,acccuracy0.7820224719101123\n",
            "epoch:17\n",
            "\ttrain\n",
            "\t\tloss0.9535077810287476,acccuracy0.7892372484791764\n",
            "\ttest\n",
            "\t\tloss0.9602876305580139,acccuracy0.7805243445692884\n",
            "epoch:18\n",
            "\ttrain\n",
            "\t\tloss0.9511850476264954,acccuracy0.7913897987833411\n",
            "\ttest\n",
            "\t\tloss0.9596813917160034,acccuracy0.7820224719101123\n",
            "epoch:19\n",
            "\ttrain\n",
            "\t\tloss0.9512836337089539,acccuracy0.7912962096396818\n",
            "\ttest\n",
            "\t\tloss0.9594687223434448,acccuracy0.7827715355805244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1oz28RhxuKO",
        "colab_type": "text"
      },
      "source": [
        "# 問題85"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XN3pqEEy8AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, i_size, e_size, h_size, o_size, embed_weight, gpu=False):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(i_size, e_size)\n",
        "    self.rnn = nn.RNN(e_size, h_size, num_layers=1, batch_first=True, bidirectional=True)\n",
        "    self.fc1 = nn.Linear(h_size*2, o_size)\n",
        "\n",
        "    nn.init.normal_(self.fc1.weight, -0.1, 0.1)\n",
        "    for word_num , weight in embed_weight:\n",
        "      self.embed.weight.data[word_num] = torch.FloatTensor(weight)\n",
        "    if gpu:\n",
        "      try_gpu(self.embed)\n",
        "\n",
        "  def forward(self, ids):\n",
        "    device = self.parameters().__next__().device\n",
        "    hidden = None\n",
        "    x = self.embed(ids.to(torch.int64).to(device))\n",
        "    x, h = self.rnn(x, hidden)\n",
        "    output = F.softmax(self.fc1(torch.cat([h[0],h[1]],dim=1)))\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7rPjuQr376B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_sorted_data, train_sorted_cate=item_sorted(train_word_ids, train_categories)\n",
        "train_dataloader = Dummy_dataloader(train_sorted_data, train_sorted_cate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nAMgZ4C4FZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "860f111b-650a-4995-e1ab-9ea7f1bbb508"
      },
      "source": [
        "model = try_gpu(Model(len(word_ID)+1, 300, 50, 4, weight, True))\n",
        "CEL = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "for epoch in range(20):\n",
        "  for datas, categories in train_dataloader.get():\n",
        "    ids = try_gpu(Variable(match_padding(datas)))\n",
        "    cate = try_gpu(Variable(torch.tensor(categories)))\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    pred = model(ids)\n",
        "\n",
        "    loss = CEL(pred, cate)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"epoch:{}\".format(epoch))\n",
        "  print(\"\\ttrain\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(train_word_ids, train_categories, model, gpu=True),\n",
        "                                        calc_accuracy(train_word_ids, train_categories, model, gpu=True)))\n",
        "  print(\"\\ttest\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(test_word_ids, test_categories, model, gpu=True),\n",
        "                                        calc_accuracy(test_word_ids, test_categories, model, gpu=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "\ttrain\n",
            "\t\tloss1.104232668876648,acccuracy0.6607393542349087\n",
            "\ttest\n",
            "\t\tloss1.1174557209014893,acccuracy0.6411985018726591\n",
            "epoch:1\n",
            "\ttrain\n",
            "\t\tloss1.0459585189819336,acccuracy0.7077211043518952\n",
            "\ttest\n",
            "\t\tloss1.0599994659423828,acccuracy0.6936329588014981\n",
            "epoch:2\n",
            "\ttrain\n",
            "\t\tloss1.0113723278045654,acccuracy0.7351427234440805\n",
            "\ttest\n",
            "\t\tloss1.0204133987426758,acccuracy0.7235955056179775\n",
            "epoch:3\n",
            "\ttrain\n",
            "\t\tloss0.9876043796539307,acccuracy0.7588207767898923\n",
            "\ttest\n",
            "\t\tloss0.9892923831939697,acccuracy0.755056179775281\n",
            "epoch:4\n",
            "\ttrain\n",
            "\t\tloss0.9766773581504822,acccuracy0.7691155825924193\n",
            "\ttest\n",
            "\t\tloss0.9769507646560669,acccuracy0.7700374531835206\n",
            "epoch:5\n",
            "\ttrain\n",
            "\t\tloss0.9697980284690857,acccuracy0.7751988769302761\n",
            "\ttest\n",
            "\t\tloss0.9702441096305847,acccuracy0.7767790262172285\n",
            "epoch:6\n",
            "\ttrain\n",
            "\t\tloss0.9636026620864868,acccuracy0.7809078146934956\n",
            "\ttest\n",
            "\t\tloss0.9636926054954529,acccuracy0.7820224719101123\n",
            "epoch:7\n",
            "\ttrain\n",
            "\t\tloss0.9584278464317322,acccuracy0.7865231633130557\n",
            "\ttest\n",
            "\t\tloss0.959244966506958,acccuracy0.7842696629213484\n",
            "epoch:8\n",
            "\ttrain\n",
            "\t\tloss0.9553338289260864,acccuracy0.7895180159101545\n",
            "\ttest\n",
            "\t\tloss0.9563356041908264,acccuracy0.7887640449438202\n",
            "epoch:9\n",
            "\ttrain\n",
            "\t\tloss0.95212721824646,acccuracy0.7931679925128685\n",
            "\ttest\n",
            "\t\tloss0.9523438215255737,acccuracy0.7925093632958802\n",
            "epoch:10\n",
            "\ttrain\n",
            "\t\tloss0.9493503570556641,acccuracy0.7954141319606925\n",
            "\ttest\n",
            "\t\tloss0.951636552810669,acccuracy0.7955056179775281\n",
            "epoch:11\n",
            "\ttrain\n",
            "\t\tloss0.946674108505249,acccuracy0.797473093121198\n",
            "\ttest\n",
            "\t\tloss0.950934886932373,acccuracy0.7917602996254681\n",
            "epoch:12\n",
            "\ttrain\n",
            "\t\tloss0.9465153813362122,acccuracy0.797473093121198\n",
            "\ttest\n",
            "\t\tloss0.9499001502990723,acccuracy0.7947565543071161\n",
            "epoch:13\n",
            "\ttrain\n",
            "\t\tloss0.9448911547660828,acccuracy0.799719232569022\n",
            "\ttest\n",
            "\t\tloss0.9501338601112366,acccuracy0.7917602996254681\n",
            "epoch:14\n",
            "\ttrain\n",
            "\t\tloss0.940750241279602,acccuracy0.8022461394478241\n",
            "\ttest\n",
            "\t\tloss0.9474965333938599,acccuracy0.797752808988764\n",
            "epoch:15\n",
            "\ttrain\n",
            "\t\tloss0.9388298988342285,acccuracy0.8040243331773514\n",
            "\ttest\n",
            "\t\tloss0.9475046396255493,acccuracy0.7962546816479401\n",
            "epoch:16\n",
            "\ttrain\n",
            "\t\tloss0.9336915612220764,acccuracy0.8097332709405709\n",
            "\ttest\n",
            "\t\tloss0.9451786279678345,acccuracy0.798501872659176\n",
            "epoch:17\n",
            "\ttrain\n",
            "\t\tloss0.9269298911094666,acccuracy0.8185306504445484\n",
            "\ttest\n",
            "\t\tloss0.9430866837501526,acccuracy0.799250936329588\n",
            "epoch:18\n",
            "\ttrain\n",
            "\t\tloss0.9185964465141296,acccuracy0.827608797379504\n",
            "\ttest\n",
            "\t\tloss0.937679648399353,acccuracy0.8052434456928839\n",
            "epoch:19\n",
            "\ttrain\n",
            "\t\tloss0.9154050946235657,acccuracy0.8322882545624708\n",
            "\ttest\n",
            "\t\tloss0.9357324838638306,acccuracy0.8067415730337079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNPeD8EzwuU2",
        "colab_type": "text"
      },
      "source": [
        "## 多層化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANgrY4Xfww1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, i_size, e_size, h_size, o_size, embed_weight, gpu=False):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(i_size, e_size)\n",
        "    self.rnn = nn.RNN(e_size, h_size, num_layers=2, batch_first=True, bidirectional=True)\n",
        "    self.fc1 = nn.Linear(h_size*2, o_size)\n",
        "\n",
        "    nn.init.normal_(self.fc1.weight, -0.1, 0.1)\n",
        "    for word_num , weight in embed_weight:\n",
        "      self.embed.weight.data[word_num] = torch.FloatTensor(weight)\n",
        "    if gpu:\n",
        "      try_gpu(self.embed)\n",
        "\n",
        "  def forward(self, ids):\n",
        "    device = self.parameters().__next__().device\n",
        "    hidden = None\n",
        "    x = self.embed(ids.to(torch.int64).to(device))\n",
        "    x, h = self.rnn(x, hidden)\n",
        "    output = F.softmax(self.fc1(torch.cat([h[-2],h[-1]],dim=1)))\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7a3IBOWw2N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_sorted_data, train_sorted_cate=item_sorted(train_word_ids, train_categories)\n",
        "train_dataloader = Dummy_dataloader(train_sorted_data, train_sorted_cate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sCM49n5w5O5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76e8fc70-d10b-4065-95ba-e500bb3c9911"
      },
      "source": [
        "model = try_gpu(Model(len(word_ID)+1, 300, 50, 4, weight, True))\n",
        "CEL = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(20):\n",
        "  for datas, categories in train_dataloader.get():\n",
        "    ids = try_gpu(Variable(match_padding(datas)))\n",
        "    cate = try_gpu(Variable(torch.tensor(categories)))\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    pred = model(ids)\n",
        "\n",
        "    loss = CEL(pred, cate)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"epoch:{}\".format(epoch))\n",
        "  print(\"\\ttrain\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(train_word_ids, train_categories, model, gpu=True),\n",
        "                                        calc_accuracy(train_word_ids, train_categories, model, gpu=True)))\n",
        "  print(\"\\ttest\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(test_word_ids, test_categories, model, gpu=True),\n",
        "                                        calc_accuracy(test_word_ids, test_categories, model, gpu=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "\ttrain\n",
            "\t\tloss1.0611757040023804,acccuracy0.6760879737950398\n",
            "\ttest\n",
            "\t\tloss1.0700427293777466,acccuracy0.6659176029962547\n",
            "epoch:1\n",
            "\ttrain\n",
            "\t\tloss0.9761713147163391,acccuracy0.7661207299953205\n",
            "\ttest\n",
            "\t\tloss0.9702117443084717,acccuracy0.7730337078651686\n",
            "epoch:2\n",
            "\ttrain\n",
            "\t\tloss0.9620311260223389,acccuracy0.7810949929808142\n",
            "\ttest\n",
            "\t\tloss0.9541111588478088,acccuracy0.7887640449438202\n",
            "epoch:3\n",
            "\ttrain\n",
            "\t\tloss0.9558996558189392,acccuracy0.786335985025737\n",
            "\ttest\n",
            "\t\tloss0.9493505358695984,acccuracy0.7962546816479401\n",
            "epoch:4\n",
            "\ttrain\n",
            "\t\tloss0.9520686268806458,acccuracy0.7909218530650445\n",
            "\ttest\n",
            "\t\tloss0.9488604068756104,acccuracy0.7955056179775281\n",
            "epoch:5\n",
            "\ttrain\n",
            "\t\tloss0.9377436637878418,acccuracy0.8071127749181095\n",
            "\ttest\n",
            "\t\tloss0.9403235912322998,acccuracy0.8029962546816479\n",
            "epoch:6\n",
            "\ttrain\n",
            "\t\tloss0.9255290627479553,acccuracy0.8187178287318672\n",
            "\ttest\n",
            "\t\tloss0.9343698024749756,acccuracy0.8104868913857678\n",
            "epoch:7\n",
            "\ttrain\n",
            "\t\tloss0.9141860008239746,acccuracy0.829293401965372\n",
            "\ttest\n",
            "\t\tloss0.9272758364677429,acccuracy0.8172284644194756\n",
            "epoch:8\n",
            "\ttrain\n",
            "\t\tloss0.9076986312866211,acccuracy0.8362189985961629\n",
            "\ttest\n",
            "\t\tloss0.9215637445449829,acccuracy0.8187265917602996\n",
            "epoch:9\n",
            "\ttrain\n",
            "\t\tloss0.8965230584144592,acccuracy0.8460458586803931\n",
            "\ttest\n",
            "\t\tloss0.9151289463043213,acccuracy0.8254681647940075\n",
            "epoch:10\n",
            "\ttrain\n",
            "\t\tloss0.8967833518981934,acccuracy0.8469817501169864\n",
            "\ttest\n",
            "\t\tloss0.9203518033027649,acccuracy0.8202247191011236\n",
            "epoch:11\n",
            "\ttrain\n",
            "\t\tloss0.882980465888977,acccuracy0.86055217594759\n",
            "\ttest\n",
            "\t\tloss0.9102440476417542,acccuracy0.8314606741573034\n",
            "epoch:12\n",
            "\ttrain\n",
            "\t\tloss0.8716948628425598,acccuracy0.8749649040711277\n",
            "\ttest\n",
            "\t\tloss0.9033699631690979,acccuracy0.8382022471910112\n",
            "epoch:13\n",
            "\ttrain\n",
            "\t\tloss0.868599534034729,acccuracy0.8776789892372485\n",
            "\ttest\n",
            "\t\tloss0.9021240472793579,acccuracy0.8397003745318352\n",
            "epoch:14\n",
            "\ttrain\n",
            "\t\tloss0.8580015897750854,acccuracy0.8886289190453908\n",
            "\ttest\n",
            "\t\tloss0.892835795879364,acccuracy0.851685393258427\n",
            "epoch:15\n",
            "\ttrain\n",
            "\t\tloss0.8562697172164917,acccuracy0.8894712213383248\n",
            "\ttest\n",
            "\t\tloss0.8938937187194824,acccuracy0.8486891385767791\n",
            "epoch:16\n",
            "\ttrain\n",
            "\t\tloss0.8506559729576111,acccuracy0.8958352831071595\n",
            "\ttest\n",
            "\t\tloss0.8896092176437378,acccuracy0.850187265917603\n",
            "epoch:17\n",
            "\ttrain\n",
            "\t\tloss0.8362454175949097,acccuracy0.9106223678053346\n",
            "\ttest\n",
            "\t\tloss0.8749233484268188,acccuracy0.8719101123595505\n",
            "epoch:18\n",
            "\ttrain\n",
            "\t\tloss0.828099250793457,acccuracy0.9173607861488068\n",
            "\ttest\n",
            "\t\tloss0.8732196688652039,acccuracy0.8666666666666667\n",
            "epoch:19\n",
            "\ttrain\n",
            "\t\tloss0.8245639801025391,acccuracy0.9219466541881142\n",
            "\ttest\n",
            "\t\tloss0.8723170757293701,acccuracy0.8711610486891386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXYBXWIZ_FER",
        "colab_type": "text"
      },
      "source": [
        "# 問題86"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-66jUfSK5bh",
        "colab_type": "text"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg3J4vmPC27S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80d63c43-7d8f-487e-a889-c8c773d3041c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_root_dir=\"./drive/My Drive\"\n",
        "import gensim\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.utils.rnn as rnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBkq6nKoC7fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_word_ids.pickle\",'rb') as f:\n",
        "  train_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_word_ids.pickle\",'rb') as f:\n",
        "  test_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_word_ids.pickle\",'rb') as f:\n",
        "  valid_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/word_ID.pickle\",'rb') as f:\n",
        "  word_ID = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_categories.pickle\",'rb') as f:\n",
        "  train_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_categories.pickle\",'rb') as f:\n",
        "  test_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_categories.pickle\",'rb') as f:\n",
        "  valid_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/weight.pickle\",'rb') as f:\n",
        "  weight = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlx_7_ZyDn0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dummy_dataloader():\n",
        "  def __init__(self, data, category, batch_size):\n",
        "    self.data = data\n",
        "    self.category = category\n",
        "    self.batch_size = batch_size\n",
        "    self.count=0\n",
        "  def get(self):\n",
        "    datas=[]\n",
        "    categories =[]\n",
        "    while self.count*self.batch_size <= len(self.data) :\n",
        "      if (self.count+1)*self.batch_size > len(self.data):\n",
        "        output_data = self.data[self.count*self.batch_size:]\n",
        "        output_category = self.category[self.count*self.batch_size:]\n",
        "        datas.append(output_data)\n",
        "        categories.append(output_category)\n",
        "        self.count = 0\n",
        "        break\n",
        "      else:\n",
        "        output_data = self.data[self.count*self.batch_size:(self.count+1)*self.batch_size]\n",
        "        output_category = self.category[self.count*self.batch_size:(self.count+1)*self.batch_size]\n",
        "        datas.append(output_data)\n",
        "        categories.append(output_category)\n",
        "        self.count +=1\n",
        "    return zip(datas, categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md2t-jRSDrqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def item_sorted(datas, categories):\n",
        "  dic = []\n",
        "  for data, category in zip(datas, categories):\n",
        "    dic.append([category, data])\n",
        "  dic=sorted(dic, key=lambda x:len(x[1]), reverse=True)\n",
        "  data_sorted=[]\n",
        "  cate_sorted=[]\n",
        "  for item in dic:\n",
        "    data_sorted.append(item[1])\n",
        "    cate_sorted.append(item[0])\n",
        "  return data_sorted, cate_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GGrgNX8DvYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def match_padding(ids):\n",
        "  max_length = max([len(id) for id in ids])\n",
        "  result = torch.zeros(len(ids), max_length)\n",
        "  for i in range(len(ids)):\n",
        "    for j in range(len(ids[i])):\n",
        "      result[i][j] = ids[i][j]\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ8iKjAbDyV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def all_model(datas, categories, model, gpu = False):\n",
        "  preds=[]\n",
        "  \n",
        "  sorted_data, sorted_cate=item_sorted(datas, categories)\n",
        "  dataloader = Dummy_dataloader(sorted_data, sorted_cate, batch_size)\n",
        "  for data, category in dataloader.get():\n",
        "    p_data = match_padding(data)\n",
        "    if gpu:\n",
        "      p_data = try_gpu(p_data)\n",
        "    for i in model(p_data):  #実質o(n) nはサンプル数\n",
        "      preds.append(i.cpu().detach().numpy().tolist())\n",
        "  return preds, sorted_cate\n",
        "\n",
        "def calc_accuracy(datas, categories, model, gpu = False):\n",
        "  preds,cate =all_model(datas, categories, model, gpu)\n",
        "  return accuracy_score(cate, [np.argmax(np.array(pred)) for pred in preds])\n",
        "\n",
        "def calc_loss(datas, categories, model, gpu = False):\n",
        "  CEL = nn.CrossEntropyLoss()\n",
        "  preds,cate =all_model(datas, categories, model, gpu)\n",
        "  loss = CEL(torch.tensor(preds), torch.tensor(cate))\n",
        "  return loss.item()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP0HvvrKK3au",
        "colab_type": "text"
      },
      "source": [
        "## 本文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISBZr9s1K3FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, i_size, e_size, h_size, o_size, embed_weight, gpu=False):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(i_size, e_size)\n",
        "    self.conv = nn.Conv1d(e_size, h_size, 3, padding=1)\n",
        "    self.fc1 = nn.Linear(h_size, o_size)\n",
        "\n",
        "    nn.init.normal_(self.fc1.weight, -0.1, 0.1)\n",
        "    for word_num , weight in embed_weight:\n",
        "      self.embed.weight.data[word_num] = torch.FloatTensor(weight)\n",
        "    if gpu:\n",
        "      try_gpu(self.embed)\n",
        "\n",
        "  def forward(self, ids):\n",
        "    device = self.parameters().__next__().device\n",
        "    x = self.embed(ids.to(torch.int64).to(device))\n",
        "    x = F.relu(self.conv(x.permute(0, 2, 1)))\n",
        "    x = F.max_pool1d(x, x.size(-1))\n",
        "    x = self.fc1(x.squeeze())\n",
        "    output = F.softmax(x, dim=1)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS6esPOfohUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_gpu(e):\n",
        "    if torch.cuda.is_available():\n",
        "        return e.cuda()\n",
        "    return e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFM5KHlCn9VD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_sorted_data, train_sorted_cate=item_sorted(train_word_ids, train_categories)\n",
        "train_dataloader = Dummy_dataloader(train_sorted_data, train_sorted_cate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW52vAGvoDSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f703f73b-879e-40c9-eb38-5cc11e45a448"
      },
      "source": [
        "model = try_gpu(Model(len(word_ID)+1, 300, 50, 4, weight, True))\n",
        "CEL = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(20):\n",
        "  for datas, categories in train_dataloader.get():\n",
        "    ids = try_gpu(Variable(match_padding(datas)))\n",
        "    cate = try_gpu(Variable(torch.tensor(categories)))\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    pred = model(ids)\n",
        "\n",
        "    loss = CEL(pred, cate)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"epoch:{}\".format(epoch))\n",
        "  print(\"\\ttrain\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(train_word_ids, train_categories, model, gpu=True),\n",
        "                                        calc_accuracy(train_word_ids, train_categories, model, gpu=True)))\n",
        "  print(\"\\ttest\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(test_word_ids, test_categories, model, gpu=True),\n",
        "                                        calc_accuracy(test_word_ids, test_categories, model, gpu=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "\ttrain\n",
            "\t\tloss1.090137243270874,acccuracy0.6495086569957885\n",
            "\ttest\n",
            "\t\tloss1.1107063293457031,acccuracy0.6194756554307116\n",
            "epoch:1\n",
            "\ttrain\n",
            "\t\tloss1.0251168012619019,acccuracy0.729995320542817\n",
            "\ttest\n",
            "\t\tloss1.0347542762756348,acccuracy0.7123595505617978\n",
            "epoch:2\n",
            "\ttrain\n",
            "\t\tloss0.9861987233161926,acccuracy0.7648104819840899\n",
            "\ttest\n",
            "\t\tloss0.9920715689659119,acccuracy0.755056179775281\n",
            "epoch:3\n",
            "\ttrain\n",
            "\t\tloss0.9650214910507202,acccuracy0.7837154890032756\n",
            "\ttest\n",
            "\t\tloss0.9706227779388428,acccuracy0.7827715355805244\n",
            "epoch:4\n",
            "\ttrain\n",
            "\t\tloss0.9548743367195129,acccuracy0.7923256902199345\n",
            "\ttest\n",
            "\t\tloss0.9619455337524414,acccuracy0.7880149812734082\n",
            "epoch:5\n",
            "\ttrain\n",
            "\t\tloss0.9486772418022156,acccuracy0.7981282171268133\n",
            "\ttest\n",
            "\t\tloss0.9580652117729187,acccuracy0.7872659176029962\n",
            "epoch:6\n",
            "\ttrain\n",
            "\t\tloss0.9444313645362854,acccuracy0.8008423022929341\n",
            "\ttest\n",
            "\t\tloss0.9555607438087463,acccuracy0.7910112359550562\n",
            "epoch:7\n",
            "\ttrain\n",
            "\t\tloss0.9411841630935669,acccuracy0.8029012634534394\n",
            "\ttest\n",
            "\t\tloss0.9527860283851624,acccuracy0.7962546816479401\n",
            "epoch:8\n",
            "\ttrain\n",
            "\t\tloss0.9398723840713501,acccuracy0.8032756200280767\n",
            "\ttest\n",
            "\t\tloss0.9533321261405945,acccuracy0.7932584269662921\n",
            "epoch:9\n",
            "\ttrain\n",
            "\t\tloss0.9397199153900146,acccuracy0.8034627983153955\n",
            "\ttest\n",
            "\t\tloss0.9537035226821899,acccuracy0.7932584269662921\n",
            "epoch:10\n",
            "\ttrain\n",
            "\t\tloss0.9364798665046692,acccuracy0.8060832943378569\n",
            "\ttest\n",
            "\t\tloss0.9515336751937866,acccuracy0.7947565543071161\n",
            "epoch:11\n",
            "\ttrain\n",
            "\t\tloss0.9347471594810486,acccuracy0.8072999532054281\n",
            "\ttest\n",
            "\t\tloss0.9507954120635986,acccuracy0.7947565543071161\n",
            "epoch:12\n",
            "\ttrain\n",
            "\t\tloss0.9335227608680725,acccuracy0.8074871314927469\n",
            "\ttest\n",
            "\t\tloss0.9508431553840637,acccuracy0.7940074906367042\n",
            "epoch:13\n",
            "\ttrain\n",
            "\t\tloss0.9316863417625427,acccuracy0.8081422554983622\n",
            "\ttest\n",
            "\t\tloss0.9504909515380859,acccuracy0.7955056179775281\n",
            "epoch:14\n",
            "\ttrain\n",
            "\t\tloss0.919090986251831,acccuracy0.8271408516612073\n",
            "\ttest\n",
            "\t\tloss0.950320303440094,acccuracy0.797752808988764\n",
            "epoch:15\n",
            "\ttrain\n",
            "\t\tloss0.905342698097229,acccuracy0.846607393542349\n",
            "\ttest\n",
            "\t\tloss0.9431528449058533,acccuracy0.8089887640449438\n",
            "epoch:16\n",
            "\ttrain\n",
            "\t\tloss0.8951030373573303,acccuracy0.8588675713617221\n",
            "\ttest\n",
            "\t\tloss0.938159167766571,acccuracy0.8112359550561797\n",
            "epoch:17\n",
            "\ttrain\n",
            "\t\tloss0.8873785138130188,acccuracy0.868039307440337\n",
            "\ttest\n",
            "\t\tloss0.9351401329040527,acccuracy0.8142322097378277\n",
            "epoch:18\n",
            "\ttrain\n",
            "\t\tloss0.8788661956787109,acccuracy0.8765559195133364\n",
            "\ttest\n",
            "\t\tloss0.9314016103744507,acccuracy0.8179775280898877\n",
            "epoch:19\n",
            "\ttrain\n",
            "\t\tloss0.8728988766670227,acccuracy0.882545624707534\n",
            "\ttest\n",
            "\t\tloss0.9294776320457458,acccuracy0.8194756554307117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v8KgQi_tY7d",
        "colab_type": "text"
      },
      "source": [
        "# 問題87"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E0bRvmjtfDa",
        "colab_type": "text"
      },
      "source": [
        "問題86で学習しました"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG68tIqetilQ",
        "colab_type": "text"
      },
      "source": [
        "# 問題88"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvZy5RSyzTOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, i_size, e_size, h_size, o_size, embed_weight, gpu=False):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(i_size, e_size)\n",
        "    self.conv = nn.Conv1d(e_size, h_size, 3, padding=1)\n",
        "    self.rnn = nn.RNN(e_size, h_size, num_layers=2, batch_first=True, bidirectional=True)\n",
        "    self.fc1 = nn.Linear(h_size, o_size)\n",
        "    self.fc2 = nn.Linear(h_size*2, o_size)\n",
        "\n",
        "    nn.init.normal_(self.fc1.weight, -0.1, 0.1)\n",
        "    nn.init.normal_(self.fc2.weight, -0.1, 0.1)\n",
        "    for word_num , weight in embed_weight:\n",
        "      self.embed.weight.data[word_num] = torch.FloatTensor(weight)\n",
        "    if gpu:\n",
        "      try_gpu(self.embed)\n",
        "\n",
        "  def forward(self, ids):\n",
        "    device = self.parameters().__next__().device\n",
        "    x = self.embed(ids.to(torch.int64).to(device))\n",
        "    x1 = F.relu(self.conv(x.permute(0, 2, 1)))\n",
        "    x1 = F.max_pool1d(x1, x1.size(-1))\n",
        "    x1 = self.fc1(x1.squeeze())\n",
        "\n",
        "    hidden = None\n",
        "    x = self.embed(ids.to(torch.int64).to(device))\n",
        "    x2, h = self.rnn(x, hidden)\n",
        "    x2 = self.fc2(torch.cat([h[-2],h[-1]],dim=1))\n",
        "    output = F.softmax(x1 + x2, dim=1)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6urLeWUnz5So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_sorted_data, train_sorted_cate=item_sorted(train_word_ids, train_categories)\n",
        "train_dataloader = Dummy_dataloader(train_sorted_data, train_sorted_cate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRe9x_XCz3f-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a4198a5b-c584-4561-eb92-2b9cfe119e4e"
      },
      "source": [
        "model = try_gpu(Model(len(word_ID)+1, 300, 50, 4, weight, True))\n",
        "CEL = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(20):\n",
        "  for datas, categories in train_dataloader.get():\n",
        "    ids = try_gpu(Variable(match_padding(datas)))\n",
        "    cate = try_gpu(Variable(torch.tensor(categories)))\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    pred = model(ids)\n",
        "\n",
        "    loss = CEL(pred, cate)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"epoch:{}\".format(epoch))\n",
        "  print(\"\\ttrain\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(train_word_ids, train_categories, model, gpu=True),\n",
        "                                        calc_accuracy(train_word_ids, train_categories, model, gpu=True)))\n",
        "  print(\"\\ttest\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(test_word_ids, test_categories, model, gpu=True),\n",
        "                                        calc_accuracy(test_word_ids, test_categories, model, gpu=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "\ttrain\n",
            "\t\tloss1.0547409057617188,acccuracy0.6940570893776322\n",
            "\ttest\n",
            "\t\tloss1.0793781280517578,acccuracy0.6539325842696629\n",
            "epoch:1\n",
            "\ttrain\n",
            "\t\tloss0.9815253615379333,acccuracy0.7645297145531118\n",
            "\ttest\n",
            "\t\tloss0.9796949028968811,acccuracy0.7647940074906368\n",
            "epoch:2\n",
            "\ttrain\n",
            "\t\tloss0.9646655321121216,acccuracy0.7786616752456715\n",
            "\ttest\n",
            "\t\tloss0.9622383117675781,acccuracy0.7842696629213484\n",
            "epoch:3\n",
            "\ttrain\n",
            "\t\tloss0.9544821977615356,acccuracy0.7897051941974731\n",
            "\ttest\n",
            "\t\tloss0.9553041458129883,acccuracy0.7910112359550562\n",
            "epoch:4\n",
            "\ttrain\n",
            "\t\tloss0.9489613175392151,acccuracy0.7932615816565278\n",
            "\ttest\n",
            "\t\tloss0.9530804753303528,acccuracy0.7895131086142322\n",
            "epoch:5\n",
            "\ttrain\n",
            "\t\tloss0.9441361427307129,acccuracy0.7987833411324287\n",
            "\ttest\n",
            "\t\tloss0.9533540606498718,acccuracy0.7902621722846442\n",
            "epoch:6\n",
            "\ttrain\n",
            "\t\tloss0.9281490445137024,acccuracy0.817313991576977\n",
            "\ttest\n",
            "\t\tloss0.9447715282440186,acccuracy0.797752808988764\n",
            "epoch:7\n",
            "\ttrain\n",
            "\t\tloss0.9127720594406128,acccuracy0.8334113242863828\n",
            "\ttest\n",
            "\t\tloss0.934903085231781,acccuracy0.8044943820224719\n",
            "epoch:8\n",
            "\ttrain\n",
            "\t\tloss0.9010558724403381,acccuracy0.8462330369677118\n",
            "\ttest\n",
            "\t\tloss0.9278855919837952,acccuracy0.8119850187265918\n",
            "epoch:9\n",
            "\ttrain\n",
            "\t\tloss0.8910669684410095,acccuracy0.85634066448292\n",
            "\ttest\n",
            "\t\tloss0.9252488017082214,acccuracy0.8164794007490637\n",
            "epoch:10\n",
            "\ttrain\n",
            "\t\tloss0.8890937566757202,acccuracy0.85774450163781\n",
            "\ttest\n",
            "\t\tloss0.9270521402359009,acccuracy0.8157303370786517\n",
            "epoch:11\n",
            "\ttrain\n",
            "\t\tloss0.8821455836296082,acccuracy0.8664482919981282\n",
            "\ttest\n",
            "\t\tloss0.9247182011604309,acccuracy0.8179775280898877\n",
            "epoch:12\n",
            "\ttrain\n",
            "\t\tloss0.873553454875946,acccuracy0.872250818905007\n",
            "\ttest\n",
            "\t\tloss0.9184800982475281,acccuracy0.8209737827715355\n",
            "epoch:13\n",
            "\ttrain\n",
            "\t\tloss0.8682607412338257,acccuracy0.8782405240992045\n",
            "\ttest\n",
            "\t\tloss0.9172105193138123,acccuracy0.8232209737827715\n",
            "epoch:14\n",
            "\ttrain\n",
            "\t\tloss0.862920343875885,acccuracy0.8832007487131492\n",
            "\ttest\n",
            "\t\tloss0.9198455214500427,acccuracy0.8247191011235955\n",
            "epoch:15\n",
            "\ttrain\n",
            "\t\tloss0.8515815138816833,acccuracy0.8948058025269069\n",
            "\ttest\n",
            "\t\tloss0.9120013117790222,acccuracy0.8329588014981273\n",
            "epoch:16\n",
            "\ttrain\n",
            "\t\tloss0.842016339302063,acccuracy0.9068788020589612\n",
            "\ttest\n",
            "\t\tloss0.9070642590522766,acccuracy0.8329588014981273\n",
            "epoch:17\n",
            "\ttrain\n",
            "\t\tloss0.8346114158630371,acccuracy0.9141787552643893\n",
            "\ttest\n",
            "\t\tloss0.904550313949585,acccuracy0.8419475655430712\n",
            "epoch:18\n",
            "\ttrain\n",
            "\t\tloss0.8264281749725342,acccuracy0.9236312587739822\n",
            "\ttest\n",
            "\t\tloss0.8996996283531189,acccuracy0.8434456928838951\n",
            "epoch:19\n",
            "\ttrain\n",
            "\t\tloss0.8198707103729248,acccuracy0.9305568554047731\n",
            "\ttest\n",
            "\t\tloss0.8959776163101196,acccuracy0.8456928838951311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPmmNgz00vB3",
        "colab_type": "text"
      },
      "source": [
        "# 問題89"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh6bIpXEacM8",
        "colab_type": "text"
      },
      "source": [
        "参考 https://qiita.com/yamaru/items/63a342c844cff056a549"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIG9NUxHaZb0",
        "colab_type": "text"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2OW1imFX5rF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "0d0237a4-2c18-4530-f2b4-795caa04aedb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 31.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 54.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=81399629ff8836cdb648d249b7d3c13ea6f6116f823f0f2bcaec67d4ccf20303\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sReQCSXjf31V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3f4ddf0d-862e-4f91-8318-4b024fc89a67"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_root_dir=\"./drive/My Drive\"\n",
        "import gensim\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.utils.rnn as rnn\n",
        "\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import time\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrI4r0-P_hX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_word_ids.pickle\",'rb') as f:\n",
        "  train_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_word_ids.pickle\",'rb') as f:\n",
        "  test_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_word_ids.pickle\",'rb') as f:\n",
        "  valid_word_ids = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/word_ID.pickle\",'rb') as f:\n",
        "  word_ID = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/train_categories.pickle\",'rb') as f:\n",
        "  train_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/test_categories.pickle\",'rb') as f:\n",
        "  test_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/valid_categories.pickle\",'rb') as f:\n",
        "  valid_categories = pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch9/weight.pickle\",'rb') as f:\n",
        "  weight = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NW6AZsqoCItb",
        "colab": {}
      },
      "source": [
        "class Dummy_dataloader():\n",
        "  def __init__(self, data, category, batch_size):\n",
        "    self.data = data\n",
        "    self.category = category\n",
        "    self.batch_size = batch_size\n",
        "    self.count=0\n",
        "  def get(self):\n",
        "    datas=[]\n",
        "    categories =[]\n",
        "    while self.count*self.batch_size <= len(self.data) :\n",
        "      if (self.count+1)*self.batch_size > len(self.data):\n",
        "        output_data = self.data[self.count*self.batch_size:]\n",
        "        output_category = self.category[self.count*self.batch_size:]\n",
        "        datas.append(output_data)\n",
        "        categories.append(output_category)\n",
        "        self.count = 0\n",
        "        break\n",
        "      else:\n",
        "        output_data = self.data[self.count*self.batch_size:(self.count+1)*self.batch_size]\n",
        "        output_category = self.category[self.count*self.batch_size:(self.count+1)*self.batch_size]\n",
        "        datas.append(output_data)\n",
        "        categories.append(output_category)\n",
        "        self.count +=1\n",
        "    return zip(datas, categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w6yu4No9CIty",
        "colab": {}
      },
      "source": [
        "def item_sorted(datas, categories):\n",
        "  dic = []\n",
        "  for data, category in zip(datas, categories):\n",
        "    dic.append([category, data])\n",
        "  dic=sorted(dic, key=lambda x:len(x[1]), reverse=True)\n",
        "  data_sorted=[]\n",
        "  cate_sorted=[]\n",
        "  for item in dic:\n",
        "    data_sorted.append(item[1])\n",
        "    cate_sorted.append(item[0])\n",
        "  return data_sorted, cate_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CInh4awrCIt4",
        "colab": {}
      },
      "source": [
        "def match_padding(ids):\n",
        "  max_length = max([len(id) for id in ids])\n",
        "  result = torch.zeros(len(ids), max_length, dtype=torch.long)\n",
        "  for i in range(len(ids)):\n",
        "    for j in range(len(ids[i])):\n",
        "      result[i][j] = ids[i][j]\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3xuz5ysCIt8",
        "colab": {}
      },
      "source": [
        "def all_model(datas, categories, model, gpu = False):\n",
        "  preds=[]\n",
        "  \n",
        "  sorted_data, sorted_cate=item_sorted(datas, categories)\n",
        "  dataloader = Dummy_dataloader(sorted_data, sorted_cate, batch_size)\n",
        "  for data, category in dataloader.get():\n",
        "    mask = torch.tensor(create_mask(data), dtype=torch.long)\n",
        "    p_data = match_padding(data)\n",
        "    if gpu:\n",
        "      mask = try_gpu(mask)\n",
        "      p_data = try_gpu(p_data)\n",
        "    for i in model(p_data, mask):  #実質o(n) nはサンプル数\n",
        "      preds.append(i.cpu().detach().numpy().tolist())\n",
        "  return preds, sorted_cate\n",
        "\n",
        "def calc_accuracy(datas, categories, model, gpu = False):\n",
        "  preds,cate =all_model(datas, categories, model, gpu)\n",
        "  return accuracy_score(cate, [np.argmax(np.array(pred)) for pred in preds])\n",
        "\n",
        "def calc_loss(datas, categories, model, gpu = False):\n",
        "  CEL = nn.CrossEntropyLoss()\n",
        "  preds,cate =all_model(datas, categories, model, gpu)\n",
        "  loss = CEL(torch.tensor(preds), torch.tensor(cate))\n",
        "  return loss.item()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq7quqvDMr_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_gpu(e):\n",
        "    if torch.cuda.is_available():\n",
        "        return e.cuda()\n",
        "    return e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMcbjR4GCPOp",
        "colab_type": "text"
      },
      "source": [
        "## 本文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rSfMJ84Coqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, otuput_size):\n",
        "    super().__init__()\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.fc = torch.nn.Linear(768, otuput_size)  # BERTの出力に合わせて768次元を指定\n",
        "\n",
        "  def forward(self, ids, mask):\n",
        "    _, out = self.bert(ids, attention_mask=mask)\n",
        "    out = self.fc(out)\n",
        "    out = F.softmax(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKfkinw6QoBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask(batchsize_ids):\n",
        "  maxlength = max([len(ids) for ids in batchsize_ids])\n",
        "  return [ [1] * len(ids) + [0]*(maxlength-len(ids))  for ids in batchsize_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GoMhFpRvDaSV",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_sorted_data, train_sorted_cate=item_sorted(train_word_ids, train_categories)\n",
        "train_dataloader = Dummy_dataloader(train_sorted_data, train_sorted_cate, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDiL1ZRLDaSd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea098dc6-58ed-499b-fac6-228595bd560d"
      },
      "source": [
        "model = try_gpu(Model(4))\n",
        "CEL = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "for epoch in range(40):\n",
        "  for datas, categories in train_dataloader.get():\n",
        "    mask = try_gpu(torch.tensor(create_mask(datas), dtype=torch.long))\n",
        "    ids = try_gpu(Variable(match_padding(datas)))\n",
        "    cate = try_gpu(Variable(torch.tensor(categories)))\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(ids, mask)\n",
        "\n",
        "    loss = CEL(pred, cate)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"epoch:{}\".format(epoch))\n",
        "  print(\"\\ttrain\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(train_word_ids, train_categories, model, gpu=True),\n",
        "                                        calc_accuracy(train_word_ids, train_categories, model, gpu=True)))\n",
        "  print(\"\\ttest\")\n",
        "  print(\"\\t\\tloss{},acccuracy{}\".format(calc_loss(test_word_ids, test_categories, model, gpu=True),\n",
        "                                        calc_accuracy(test_word_ids, test_categories, model, gpu=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "\ttrain\n",
            "\t\tloss1.106292724609375,acccuracy0.6339728591483388\n",
            "\ttest\n",
            "\t\tloss1.1176788806915283,acccuracy0.6157303370786517\n",
            "epoch:1\n",
            "\ttrain\n",
            "\t\tloss0.9820935726165771,acccuracy0.7597566682264857\n",
            "\ttest\n",
            "\t\tloss0.9869040250778198,acccuracy0.755056179775281\n",
            "epoch:2\n",
            "\ttrain\n",
            "\t\tloss0.9486721158027649,acccuracy0.7861488067384184\n",
            "\ttest\n",
            "\t\tloss0.9702041745185852,acccuracy0.7730337078651686\n",
            "epoch:3\n",
            "\ttrain\n",
            "\t\tloss0.9441455602645874,acccuracy0.7957884885353299\n",
            "\ttest\n",
            "\t\tloss0.9761539697647095,acccuracy0.7588014981273409\n",
            "epoch:4\n",
            "\ttrain\n",
            "\t\tloss1.0052461624145508,acccuracy0.7327094057089377\n",
            "\ttest\n",
            "\t\tloss1.041250228881836,acccuracy0.6928838951310862\n",
            "epoch:5\n",
            "\ttrain\n",
            "\t\tloss0.9206914305686951,acccuracy0.8206832007487131\n",
            "\ttest\n",
            "\t\tloss0.9565999507904053,acccuracy0.7812734082397004\n",
            "epoch:6\n",
            "\ttrain\n",
            "\t\tloss0.9362585544586182,acccuracy0.8029948525970987\n",
            "\ttest\n",
            "\t\tloss0.982696533203125,acccuracy0.7558052434456929\n",
            "epoch:7\n",
            "\ttrain\n",
            "\t\tloss0.961430013179779,acccuracy0.7752924660739354\n",
            "\ttest\n",
            "\t\tloss1.0037000179290771,acccuracy0.7318352059925094\n",
            "epoch:8\n",
            "\ttrain\n",
            "\t\tloss0.9323288202285767,acccuracy0.8084230229293402\n",
            "\ttest\n",
            "\t\tloss0.9892604351043701,acccuracy0.7438202247191011\n",
            "epoch:9\n",
            "\ttrain\n",
            "\t\tloss0.909336268901825,acccuracy0.8329433785680861\n",
            "\ttest\n",
            "\t\tloss0.9738184213638306,acccuracy0.7632958801498128\n",
            "epoch:10\n",
            "\ttrain\n",
            "\t\tloss0.8739392757415771,acccuracy0.8698175011698643\n",
            "\ttest\n",
            "\t\tloss0.936314582824707,acccuracy0.8029962546816479\n",
            "epoch:11\n",
            "\ttrain\n",
            "\t\tloss0.8857776522636414,acccuracy0.85634066448292\n",
            "\ttest\n",
            "\t\tloss0.9515938758850098,acccuracy0.7880149812734082\n",
            "epoch:12\n",
            "\ttrain\n",
            "\t\tloss0.856976330280304,acccuracy0.8858212447356106\n",
            "\ttest\n",
            "\t\tloss0.9415998458862305,acccuracy0.797752808988764\n",
            "epoch:13\n",
            "\ttrain\n",
            "\t\tloss0.8487241864204407,acccuracy0.8940570893776322\n",
            "\ttest\n",
            "\t\tloss0.9344666004180908,acccuracy0.8059925093632959\n",
            "epoch:14\n",
            "\ttrain\n",
            "\t\tloss0.8251466155052185,acccuracy0.9184838558727187\n",
            "\ttest\n",
            "\t\tloss0.916397750377655,acccuracy0.8254681647940075\n",
            "epoch:15\n",
            "\ttrain\n",
            "\t\tloss0.8207342028617859,acccuracy0.9225081890500701\n",
            "\ttest\n",
            "\t\tloss0.9254547953605652,acccuracy0.8134831460674158\n",
            "epoch:16\n",
            "\ttrain\n",
            "\t\tloss0.8136631846427917,acccuracy0.9295273748245203\n",
            "\ttest\n",
            "\t\tloss0.9062063097953796,acccuracy0.8344569288389513\n",
            "epoch:17\n",
            "\ttrain\n",
            "\t\tloss0.8269991874694824,acccuracy0.9158633598502574\n",
            "\ttest\n",
            "\t\tloss0.934579610824585,acccuracy0.8052434456928839\n",
            "epoch:18\n",
            "\ttrain\n",
            "\t\tloss0.8082094192504883,acccuracy0.9354234908750585\n",
            "\ttest\n",
            "\t\tloss0.912577748298645,acccuracy0.8277153558052435\n",
            "epoch:19\n",
            "\ttrain\n",
            "\t\tloss0.8106204271316528,acccuracy0.9323350491343004\n",
            "\ttest\n",
            "\t\tloss0.9087200164794922,acccuracy0.8307116104868913\n",
            "epoch:20\n",
            "\ttrain\n",
            "\t\tloss0.8108825087547302,acccuracy0.932522227421619\n",
            "\ttest\n",
            "\t\tloss0.9236437082290649,acccuracy0.8179775280898877\n",
            "epoch:21\n",
            "\ttrain\n",
            "\t\tloss0.8229705691337585,acccuracy0.9207299953205428\n",
            "\ttest\n",
            "\t\tloss0.9114747643470764,acccuracy0.8307116104868913\n",
            "epoch:22\n",
            "\ttrain\n",
            "\t\tloss0.8058573007583618,acccuracy0.9377632194665418\n",
            "\ttest\n",
            "\t\tloss0.8920894861221313,acccuracy0.850936329588015\n",
            "epoch:23\n",
            "\ttrain\n",
            "\t\tloss0.8050315976142883,acccuracy0.9386991109031352\n",
            "\ttest\n",
            "\t\tloss0.8959689140319824,acccuracy0.8471910112359551\n",
            "epoch:24\n",
            "\ttrain\n",
            "\t\tloss0.8004035353660583,acccuracy0.9432849789424427\n",
            "\ttest\n",
            "\t\tloss0.8804139494895935,acccuracy0.8621722846441947\n",
            "epoch:25\n",
            "\ttrain\n",
            "\t\tloss0.8046339154243469,acccuracy0.9386055217594759\n",
            "\ttest\n",
            "\t\tloss0.9014705419540405,acccuracy0.8411985018726592\n",
            "epoch:26\n",
            "\ttrain\n",
            "\t\tloss0.796305239200592,acccuracy0.9471221338324755\n",
            "\ttest\n",
            "\t\tloss0.8953449726104736,acccuracy0.847940074906367\n",
            "epoch:27\n",
            "\ttrain\n",
            "\t\tloss0.8058772087097168,acccuracy0.9373888628919045\n",
            "\ttest\n",
            "\t\tloss0.8923476934432983,acccuracy0.849438202247191\n",
            "epoch:28\n",
            "\ttrain\n",
            "\t\tloss0.796513557434082,acccuracy0.9471221338324755\n",
            "\ttest\n",
            "\t\tloss0.9014396071434021,acccuracy0.8411985018726592\n",
            "epoch:29\n",
            "\ttrain\n",
            "\t\tloss0.7997153997421265,acccuracy0.9437529246607393\n",
            "\ttest\n",
            "\t\tloss0.8963244557380676,acccuracy0.8441947565543071\n",
            "epoch:30\n",
            "\ttrain\n",
            "\t\tloss0.8010465502738953,acccuracy0.942536265793168\n",
            "\ttest\n",
            "\t\tloss0.9204077124595642,acccuracy0.8224719101123595\n",
            "epoch:31\n",
            "\ttrain\n",
            "\t\tloss0.812187671661377,acccuracy0.9310248011230697\n",
            "\ttest\n",
            "\t\tloss0.9309347867965698,acccuracy0.8104868913857678\n",
            "epoch:32\n",
            "\ttrain\n",
            "\t\tloss0.7948315143585205,acccuracy0.9485259709873655\n",
            "\ttest\n",
            "\t\tloss0.8955059051513672,acccuracy0.847940074906367\n",
            "epoch:33\n",
            "\ttrain\n",
            "\t\tloss0.792397141456604,acccuracy0.9511464670098269\n",
            "\ttest\n",
            "\t\tloss0.8960366249084473,acccuracy0.8456928838951311\n",
            "epoch:34\n",
            "\ttrain\n",
            "\t\tloss0.7933917045593262,acccuracy0.9503041647168928\n",
            "\ttest\n",
            "\t\tloss0.8825199604034424,acccuracy0.8614232209737828\n",
            "epoch:35\n",
            "\ttrain\n",
            "\t\tloss0.7932366132736206,acccuracy0.9502105755732335\n",
            "\ttest\n",
            "\t\tloss0.8857041597366333,acccuracy0.8576779026217228\n",
            "epoch:36\n",
            "\ttrain\n",
            "\t\tloss0.7898809313774109,acccuracy0.9538605521759476\n",
            "\ttest\n",
            "\t\tloss0.8847377300262451,acccuracy0.8591760299625468\n",
            "epoch:37\n",
            "\ttrain\n",
            "\t\tloss0.7917527556419373,acccuracy0.9518015910154423\n",
            "\ttest\n",
            "\t\tloss0.8872616291046143,acccuracy0.8539325842696629\n",
            "epoch:38\n",
            "\ttrain\n",
            "\t\tloss0.8158882260322571,acccuracy0.9276555919513336\n",
            "\ttest\n",
            "\t\tloss0.9059759378433228,acccuracy0.8367041198501872\n",
            "epoch:39\n",
            "\ttrain\n",
            "\t\tloss0.8143979907035828,acccuracy0.9287786616752457\n",
            "\ttest\n",
            "\t\tloss0.9367682933807373,acccuracy0.8067415730337079\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}