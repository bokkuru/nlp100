{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter08.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4SkpJY0N85P",
        "colab_type": "code",
        "outputId": "18dd64f0-f5b8-44fb-821e-98ad4f128d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_root_dir=\"./drive/My Drive\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llbr-5tZRJrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Article:\n",
        "  def __init__(self,ID,TITLE,CATEGORY):\n",
        "    self.id=ID\n",
        "    self.title=TITLE\n",
        "    self.category=CATEGORY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZTLam5TLOiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_colab=drive_root_dir+\"/Colab Notebooks\"\n",
        "test_articles=[]\n",
        "train_articles=[]\n",
        "valid_articles=[]\n",
        "with open(drive_colab+\"/test.txt\") as test, open(drive_colab+\"/train.txt\") as train, open(drive_colab+\"/valid.txt\") as valid:\n",
        "  for line in test.readlines():\n",
        "    elms=line.split('\\t')\n",
        "    article=Article(elms[0],elms[1],elms[4])\n",
        "    test_articles.append(article)\n",
        "  for line in train.readlines():\n",
        "    elms=line.split('\\t')\n",
        "    article=Article(elms[0],elms[1],elms[4])\n",
        "    train_articles.append(article)\n",
        "  for line in valid.readlines():\n",
        "    elms=line.split('\\t')\n",
        "    article=Article(elms[0],elms[1],elms[4])\n",
        "    valid_articles.append(article)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP-RWcm5X-9_",
        "colab_type": "code",
        "outputId": "465259ba-e526-4d2b-b82c-e9ba262d006e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.1.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei-2T8BaZuaZ",
        "colab_type": "code",
        "outputId": "f70af5ff-dfe7-42a3-86a0-ff67d2b6b038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.4)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.13.19)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.16.19)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XnXgGz5YVM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1thRhQf6aSrD",
        "colab_type": "code",
        "outputId": "2f4df288-e89e-45e1-b081-1d8992494046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!rm GoogleNews-vectors-negative300.bin.gz GoogleNews-vectors-negative300.bin\n",
        "!wget -q https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
        "!gunzip -n GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'GoogleNews-vectors-negative300.bin.gz': No such file or directory\n",
            "rm: cannot remove 'GoogleNews-vectors-negative300.bin': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SolcHQXraKiD",
        "colab_type": "code",
        "outputId": "acddf879-27ce-4cf6-aff9-62e59ca5b1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3_eTM0b4AiK",
        "colab_type": "code",
        "outputId": "e7ddcd72-3dd1-480a-a989-137c2c3d7b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install numpy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NcKjhPk38Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrG4IM8B4dVQ",
        "colab_type": "code",
        "outputId": "05100fa3-b91c-4c74-aee9-718bfe38bab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install stemming"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stemming\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/eb/fd53fb51b83a4e3b8e98cfec2fa9e4b99401fce5177ec346e4a5c61df71e/stemming-1.0.1.tar.gz\n",
            "Building wheels for collected packages: stemming\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-cp36-none-any.whl size=11139 sha256=9ea09f6a251a519c760ded46f918d0364a2d0e399f5585415590b1052674325a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/05/2e/2ddeb64d4464b854b48323f9676528c17560da7d153db7b0e2\n",
            "Successfully built stemming\n",
            "Installing collected packages: stemming\n",
            "Successfully installed stemming-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swYtiCf_4fjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from stemming.porter2 import stem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xenTOaKi87Yr",
        "colab_type": "text"
      },
      "source": [
        "## 問題70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V24o4WIUbaub",
        "colab_type": "code",
        "outputId": "623f3a4c-7501-4cce-9761-06243317c3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "def create_data(articles):\n",
        "  cats=[]\n",
        "  vecs=[]\n",
        "  for article in articles:\n",
        "    words=nlp.make_doc(article.title)\n",
        "    vec=[] \n",
        "    for word in words:\n",
        "      tmp=stem(word.lemma_.lower())\n",
        "      if tmp in model:\n",
        "        vec.append(model[tmp])\n",
        "    vec=np.array(vec)\n",
        "    vec=np.mean(vec,axis=0)\n",
        "    if article.category=='b':\n",
        "      cat=0\n",
        "    elif article.category=='t':\n",
        "      cat=1\n",
        "    elif article.category=='e':\n",
        "      cat=2\n",
        "    elif article.category=='m':\n",
        "      cat=3\n",
        "    cats.append(cat)\n",
        "    vecs.append(vec)\n",
        "  return vecs,cats\n",
        "\n",
        "train_x=[]\n",
        "train_y=[]\n",
        "test_x=[]\n",
        "test_y=[]\n",
        "valid_x=[]\n",
        "valid_y=[]\n",
        "nlp=spacy.load('en')\n",
        "train_x,train_y = create_data(train_articles)\n",
        "test_x,test_y = create_data(test_articles)\n",
        "valid_x,valid_y = create_data(valid_articles)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DiFnFuF8_WQ",
        "colab_type": "code",
        "outputId": "4adc1a7d-87d3-42bd-a0f0-ff8210789454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        }
      },
      "source": [
        "print(train_y[0])\n",
        "print(train_x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "[ 0.01674398  0.02593655 -0.0020006   0.01987033 -0.07628039  0.02746582\n",
            "  0.02934986 -0.04082574  0.07891846  0.01909044 -0.10150824 -0.14477539\n",
            "  0.02598063  0.0543891  -0.10061985  0.05054389  0.02968089  0.04136827\n",
            " -0.04498969 -0.02448188 -0.05888536  0.07421875  0.08021376 -0.0491511\n",
            "  0.01045058  0.00535075 -0.15445964  0.06081814  0.03857252 -0.00668844\n",
            "  0.00761922  0.05213759 -0.0285102  -0.02175225  0.03401693 -0.00785997\n",
            "  0.00061035  0.1152988   0.05091688  0.08462185  0.07815867 -0.00705295\n",
            "  0.0803638  -0.03783502  0.02484809 -0.07800378 -0.03815375 -0.04409451\n",
            "  0.06366306  0.02764214 -0.01350911  0.06863827 -0.00243462  0.00359429\n",
            "  0.00305854  0.04418945 -0.03768582 -0.01658461  0.01452637 -0.03605143\n",
            " -0.07307943  0.07854547 -0.06221517 -0.0338406  -0.00104947 -0.07685004\n",
            " -0.06582303  0.0465427  -0.05752563  0.05455187  0.04640028  0.03554959\n",
            "  0.0626865  -0.01101345 -0.1265191   0.00093587  0.11870829  0.08871799\n",
            "  0.03603787  0.10325114 -0.00325521 -0.04852803  0.06368341 -0.0600179\n",
            "  0.01551649 -0.07019636 -0.12871784  0.11249457 -0.01272244  0.02077908\n",
            " -0.03048028  0.01512655 -0.0600569  -0.07722982 -0.03405084 -0.00059679\n",
            "  0.01283773  0.0252143   0.01738146  0.01548937 -0.01956367  0.04679362\n",
            "  0.04783037 -0.02922228 -0.05137804 -0.02246094 -0.00387912 -0.01621501\n",
            "  0.03160095 -0.05214606 -0.1063368  -0.13899739 -0.02045356 -0.03229904\n",
            "  0.07691786  0.01456261  0.02662489 -0.04758029  0.07226562  0.00733778\n",
            " -0.02692668 -0.0227729  -0.12061903  0.03799777 -0.00701226 -0.08052148\n",
            " -0.09594388  0.01296658 -0.02486844  0.02651639 -0.02618408 -0.06709798\n",
            " -0.01605903 -0.00088591  0.00337389 -0.01799859 -0.02611118 -0.02330187\n",
            "  0.07253689  0.0245836   0.07493761  0.03040229  0.08379449 -0.06339857\n",
            " -0.02069092 -0.00253635 -0.06332736  0.02088759 -0.03192478 -0.0504286\n",
            "  0.01841227 -0.04915364 -0.06796604  0.01299371 -0.07840983  0.0379503\n",
            " -0.0024448  -0.05095079 -0.03296576 -0.0318061  -0.10375977  0.05842421\n",
            "  0.04318322  0.04836697 -0.02448188 -0.08946398  0.0093316  -0.0599094\n",
            " -0.05838776  0.0301378  -0.0964898  -0.04912652  0.00331709 -0.10472277\n",
            " -0.00769891  0.05756293  0.06922743 -0.11789279  0.04000515 -0.04277547\n",
            " -0.04327393 -0.03745015  0.0430976  -0.02208116 -0.00147841  0.09382025\n",
            " -0.03480233  0.04964193  0.06089952  0.0446913   0.03643799  0.00991016\n",
            "  0.01737128  0.01729329  0.052653    0.06159804 -0.03153483 -0.08443366\n",
            " -0.08131239 -0.08557807 -0.01117622  0.01630317 -0.08542548 -0.04500665\n",
            "  0.00713433 -0.04120551 -0.02375624 -0.02708605  0.01909722  0.01635742\n",
            "  0.00462511  0.05404324 -0.03418986 -0.03274536 -0.0858629  -0.00505405\n",
            "  0.07751465 -0.0618693  -0.10394965  0.09817229 -0.04785156 -0.04255846\n",
            "  0.02993902  0.0014445   0.09299045 -0.03968303  0.08863661  0.00097995\n",
            "  0.0167372  -0.01989746 -0.04006619 -0.00900608  0.00151571  0.07347616\n",
            "  0.04516008  0.03792996 -0.03960164 -0.01681519  0.0359336   0.02460734\n",
            "  0.0663147  -0.0074802   0.04259576 -0.05066957 -0.00742594  0.04688856\n",
            "  0.04239909  0.11086697 -0.02749295 -0.03944227 -0.03627523  0.03594293\n",
            "  0.1007487   0.07261149  0.04802789 -0.01058621 -0.00899929  0.08128527\n",
            " -0.10625543 -0.09811825  0.00245497 -0.02553982  0.01510281  0.02131483\n",
            " -0.0112576   0.12095812 -0.0452101  -0.07821994  0.01951769 -0.06858996\n",
            "  0.00400289  0.08516439  0.04979112  0.01589542  0.02864583 -0.03070747\n",
            " -0.0528361  -0.16718207 -0.1149292   0.0494656   0.0081164  -0.01848772\n",
            "  0.01482815  0.01756795  0.03789605  0.01493369 -0.06808811  0.00129191\n",
            "  0.01955838  0.00836266 -0.02292209  0.05451117  0.00835503  0.0105523\n",
            " -0.00882975 -0.06417847 -0.01875814  0.00037977 -0.0198449  -0.01226128]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTCsdSt49NRV",
        "colab_type": "text"
      },
      "source": [
        "## 問題71"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkiZ71LN9iyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(a):\n",
        "    a_max = np.max(a)\n",
        "    x = np.exp(a-a_max)\n",
        "    u = np.sum(x)\n",
        "    return x/u"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpm10vsYSOSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W=np.random.rand(len(train_x[0]),4)\n",
        "x1=np.matrix(train_x[0])\n",
        "W=np.matrix(W)\n",
        "y1=softmax(np.dot(x1,W))[0]\n",
        "x14=np.matrix(train_x[0:4])\n",
        "Y=[]\n",
        "tmp=np.dot(x14,W)\n",
        "for i in tmp:\n",
        "  Y.append(softmax(i).tolist()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHPajlP0oQWg",
        "colab_type": "code",
        "outputId": "3c4562e7-30c5-46da-b0ed-088639250d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(y1[0])\n",
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.24284469 0.23785244 0.21174597 0.30755689]]\n",
            "[[0.24284469477474319, 0.2378524367343321, 0.21174597484433194, 0.3075568936465928], [0.17336179181531028, 0.3535192675974743, 0.1873258885038081, 0.2857930520834073], [0.24339242177157425, 0.3795735293306232, 0.1628849799176224, 0.2141490689801799], [0.21947559044070206, 0.34984648202752006, 0.17740871922557244, 0.2532692083062054]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kddooSfZw4fy",
        "colab_type": "text"
      },
      "source": [
        "## 問題72"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv4VUeAEim5U",
        "colab_type": "code",
        "outputId": "3d00cf3d-f750-44eb-a5f9-89e92bc748b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "!pip3 install torch==1.3.0+cpu torchvision==0.4.1+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.3.0+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torch-1.3.0%2Bcpu-cp36-cp36m-linux_x86_64.whl (111.6MB)\n",
            "\u001b[K     |████████████████████████████████| 111.6MB 85kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.1+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.4.1%2Bcpu-cp36-cp36m-linux_x86_64.whl (13.5MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5MB 330kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.0+cpu) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.1+cpu) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.1+cpu) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torch-1.3.0+cpu torchvision-0.4.1+cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKjApnei2jgW",
        "colab_type": "text"
      },
      "source": [
        "クロスエントロピー"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUMjFG0o-q7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy(y,ans):\n",
        "  return -np.log(y[0,ans])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6lvTVYfyKcr",
        "colab_type": "code",
        "outputId": "a9a9ba06-3269-4bd8-8f88-9eab05d9a921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "l1=cross_entropy(y1,train_y[0])\n",
        "l14=0\n",
        "for i in range(4):\n",
        "  tmp_x=np.matrix(train_x[i])\n",
        "  tmp_y=softmax(np.dot(tmp_x,W))[0]\n",
        "  l14+=cross_entropy(tmp_y,train_y[i])\n",
        "l14=l14/4\n",
        "print(l1)\n",
        "print(l14)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3498163973675004\n",
            "1.3998886030015978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvZJP3zT2g9M",
        "colab_type": "text"
      },
      "source": [
        "勾配"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3H2gvuX2gFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLm5CdeF12V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def torch_softmax(a):\n",
        "    a_max = torch.max(a)\n",
        "    x = torch.exp(a-a_max)\n",
        "    u = torch.sum(x)\n",
        "    return x/u\n",
        "\n",
        "def gradient(x,y,weight):\n",
        "  X = torch.tensor([x])\n",
        "  W = torch.tensor(weight,requires_grad=True).float()\n",
        "  print(-torch.log(torch_softmax(torch.mm(X,W))[0,y]))\n",
        "  calc = -torch.log(torch_softmax(torch.mm(X,W))[0,y])\n",
        "  calc.backward()\n",
        "  return W.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa0GmNpb3V7x",
        "colab_type": "code",
        "outputId": "f1ef30f9-6b8c-4517-b08e-1ee55ba954bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "W = torch.tensor(W,requires_grad=True).float()\n",
        "print(gradient(train_x[0],train_y[0],W))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.5524, grad_fn=<NegBackward>)\n",
            "tensor([[ 4.0662e-03,  3.9826e-03, -1.3199e-02,  5.1497e-03],\n",
            "        [ 6.2986e-03,  6.1691e-03, -2.0445e-02,  7.9770e-03],\n",
            "        [-4.8583e-04, -4.7585e-04,  1.5770e-03, -6.1530e-04],\n",
            "        ...,\n",
            "        [ 9.2226e-05,  9.0330e-05, -2.9936e-04,  1.1680e-04],\n",
            "        [-4.8192e-03, -4.7202e-03,  1.5643e-02, -6.1034e-03],\n",
            "        [-2.9776e-03, -2.9164e-03,  9.6650e-03, -3.7710e-03]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrCasBAZAItZ",
        "colab_type": "text"
      },
      "source": [
        "koyamaさんのを参考にしました"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMIOED6QBj4B",
        "colab_type": "code",
        "outputId": "1e5c0035-3c09-415d-863b-5c876865344c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(type(train_x[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhDolP-CAHv9",
        "colab_type": "code",
        "outputId": "6af0813e-2e74-4a2a-8a6c-40e7ef10741a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "tmp = torch.tensor([train_x[0].tolist()])\n",
        "W = torch.tensor(W,requires_grad=True).float()\n",
        "tmp2 = torch.tensor([train_y[0]])\n",
        "calc = loss(torch.mm(tmp, W), tmp2)\n",
        "calc.backward()\n",
        "print(W.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 4.0662e-03,  3.9826e-03, -1.3199e-02,  5.1497e-03],\n",
            "        [ 6.2986e-03,  6.1691e-03, -2.0445e-02,  7.9770e-03],\n",
            "        [-4.8583e-04, -4.7585e-04,  1.5770e-03, -6.1530e-04],\n",
            "        ...,\n",
            "        [ 9.2226e-05,  9.0330e-05, -2.9936e-04,  1.1680e-04],\n",
            "        [-4.8192e-03, -4.7202e-03,  1.5643e-02, -6.1034e-03],\n",
            "        [-2.9776e-03, -2.9164e-03,  9.6650e-03, -3.7710e-03]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwsOBP6CDfyA",
        "colab_type": "code",
        "outputId": "3417efff-fdad-419d-a77a-848db0984f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "tmp = torch.tensor(train_x[:4])\n",
        "W = torch.tensor(W,requires_grad=True).float()\n",
        "tmp2 = torch.tensor(train_y[:4])\n",
        "calc = loss(torch.mm(tmp, W), tmp2)\n",
        "print(calc)\n",
        "calc.backward()\n",
        "print(W.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.5924, grad_fn=<NllLossBackward>)\n",
            "tensor([[ 0.0162, -0.0007, -0.0169,  0.0014],\n",
            "        [-0.0019, -0.0027,  0.0059, -0.0013],\n",
            "        [ 0.0038, -0.0036,  0.0020, -0.0022],\n",
            "        ...,\n",
            "        [-0.0132, -0.0005,  0.0149, -0.0012],\n",
            "        [ 0.0016, -0.0028,  0.0040, -0.0028],\n",
            "        [-0.0062,  0.0079, -0.0067,  0.0049]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_lEp6rcDv6q",
        "colab_type": "text"
      },
      "source": [
        "## 問題73"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4joBr0sEGEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v-Im-JhEHFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = np.random.rand(len(train_x[0]),4)\n",
        "W = np.matrix(W)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "W = torch.tensor(W, dtype=torch.float, requires_grad=True)\n",
        "op = optim.SGD([W],lr=0.1)\n",
        "tmp_train_x = torch.tensor(train_x)\n",
        "tmp_train_y = torch.tensor(train_y)\n",
        "for epoch in range(10000):\n",
        "  calc_train = loss(torch.mm(tmp_train_x, W), tmp_train_y)\n",
        "  op.zero_grad()\n",
        "  calc_train.backward()\n",
        "  op.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lBhHrwtHToJ",
        "colab_type": "text"
      },
      "source": [
        "## 問題74"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQA7G6_6JJIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(x,weight):\n",
        "  X = torch.tensor([x])\n",
        "  W = torch.tensor(weight,requires_grad=True).float()\n",
        "  preds=torch_softmax(torch.mm(X,W))[0]\n",
        "  max_i=0\n",
        "  max_pred=0\n",
        "  for i,pred in enumerate(preds):\n",
        "    if max_pred<pred:\n",
        "      max_i=i\n",
        "      max_pred=pred\n",
        "  return max_i\n",
        "def calc_accuracy(x,y,weight):\n",
        "  count=0\n",
        "  for i in range(len(x)):\n",
        "    pre = predict(x[i],weight)\n",
        "    if y[i] == pre:\n",
        "      count+=1\n",
        "  return count/len(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMrn7mBvKPyX",
        "colab_type": "code",
        "outputId": "53427f57-a15c-4088-82c3-86e1c826047c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(calc_accuracy(train_x,train_y,W))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8465138043986897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnDyZRpdK7Lh",
        "colab_type": "code",
        "outputId": "2abefe8e-8a66-484d-84a0-cedeb1b2f3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "count=0\n",
        "print(calc_accuracy(test_x,test_y,W))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.850936329588015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q-b-rf0stje",
        "colab_type": "text"
      },
      "source": [
        "## 問題75"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a6dLgI1swGC",
        "colab_type": "code",
        "outputId": "aba83351-e31d-4ac8-a5b1-0778a98a668e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "W=np.random.rand(len(train_x[0]),4)\n",
        "W=np.matrix(W)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "W = torch.tensor(W, dtype=torch.float, requires_grad=True)\n",
        "op = optim.SGD([W],lr=0.1)\n",
        "train_loss=[]\n",
        "train_accuracy=[]\n",
        "test_loss=[]\n",
        "test_accuracy=[]\n",
        "tmp_test_x = torch.tensor(test_x)\n",
        "tmp_test_y = torch.tensor(test_y)\n",
        "for epoch in range(1000):\n",
        "  calc_train = loss(torch.mm(tmp_train_x, W), tmp_train_y)\n",
        "  calc_test = loss(torch.mm(tmp_test_x, W), tmp_test_y)\n",
        "  train_loss.append(calc_train.item())\n",
        "  test_loss.append(calc_test.item())\n",
        "  train_accuracy.append(calc_accuracy(train_x,train_y,W))\n",
        "  test_accuracy.append(calc_accuracy(test_x,test_y,W))\n",
        "  op.zero_grad()\n",
        "  calc_train.backward()\n",
        "  op.step()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL1rqBjPYkoT",
        "colab_type": "code",
        "outputId": "befaa5b0-ea71-4505-ea42-85842b0708e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "!pip install matplotlib"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcgqOAiahHUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTdJj7BN6OII",
        "colab_type": "code",
        "outputId": "46019c25-1522-4762-e30e-9c95c04da668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "epochs = range(len(train_loss))\n",
        "plt.plot(epochs,train_loss, label=\"train_loss\")\n",
        "plt.plot(epochs,test_loss, label=\"test_loss\")\n",
        "plt.plot(epochs,train_accuracy, label=\"train_accuracy\")\n",
        "plt.plot(epochs,test_accuracy, label=\"test_accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEZHcvnbibfo",
        "colab_type": "text"
      },
      "source": [
        "## 問題76"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riD2vDl-s433",
        "colab_type": "code",
        "outputId": "813d9c44-d519-4f70-d5e5-724354c4798f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "W=np.random.rand(len(train_x[0]),4)\n",
        "W=np.matrix(W)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "W = torch.tensor(W, dtype=torch.float, requires_grad=True)\n",
        "op = optim.SGD([W],lr=0.1)\n",
        "epoch_datas=[]\n",
        "tmp_test_x = torch.tensor(test_x)\n",
        "tmp_test_y = torch.tensor(test_y)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/nlp76.txt\",'w') as f:\n",
        "  for epoch in range(1000):\n",
        "    f.write(\"#{}#\\n\".format(epoch))\n",
        "    f.write(str(W))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(str(op.param_groups))\n",
        "    f.write(\"\\n\")\n",
        "    calc_train = loss(torch.mm(tmp_train_x, W), tmp_train_y)\n",
        "    op.zero_grad()\n",
        "    calc_train.backward()\n",
        "    op.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aITYyv2ByP5D",
        "colab_type": "code",
        "outputId": "d2666314-2678-4ce7-da59-47838551c0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        }
      },
      "source": [
        "with open(drive_root_dir+\"/Colab Notebooks/nlp76.txt\",'r') as f:\n",
        "  for i in range(50):\n",
        "    print(f.readline(),end=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#0#\n",
            "tensor([[0.7614, 0.7507, 0.1989, 0.7326],\n",
            "        [0.1791, 0.1124, 0.8847, 0.5423],\n",
            "        [0.1891, 0.0270, 0.0891, 0.0563],\n",
            "        ...,\n",
            "        [0.7948, 0.9030, 0.4384, 0.5296],\n",
            "        [0.8746, 0.0587, 0.6500, 0.2643],\n",
            "        [0.7781, 0.7099, 0.2080, 0.8880]], requires_grad=True)\n",
            "[{'params': [tensor([[0.7614, 0.7507, 0.1989, 0.7326],\n",
            "        [0.1791, 0.1124, 0.8847, 0.5423],\n",
            "        [0.1891, 0.0270, 0.0891, 0.0563],\n",
            "        ...,\n",
            "        [0.7948, 0.9030, 0.4384, 0.5296],\n",
            "        [0.8746, 0.0587, 0.6500, 0.2643],\n",
            "        [0.7781, 0.7099, 0.2080, 0.8880]], requires_grad=True)], 'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n",
            "#1#\n",
            "tensor([[0.7612, 0.7508, 0.1989, 0.7328],\n",
            "        [0.1794, 0.1122, 0.8851, 0.5418],\n",
            "        [0.1887, 0.0271, 0.0894, 0.0564],\n",
            "        ...,\n",
            "        [0.7950, 0.9033, 0.4371, 0.5305],\n",
            "        [0.8748, 0.0586, 0.6497, 0.2645],\n",
            "        [0.7768, 0.7098, 0.2089, 0.8884]], requires_grad=True)\n",
            "[{'params': [tensor([[0.7612, 0.7508, 0.1989, 0.7328],\n",
            "        [0.1794, 0.1122, 0.8851, 0.5418],\n",
            "        [0.1887, 0.0271, 0.0894, 0.0564],\n",
            "        ...,\n",
            "        [0.7950, 0.9033, 0.4371, 0.5305],\n",
            "        [0.8748, 0.0586, 0.6497, 0.2645],\n",
            "        [0.7768, 0.7098, 0.2089, 0.8884]], requires_grad=True)], 'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n",
            "#2#\n",
            "tensor([[0.7609, 0.7510, 0.1989, 0.7329],\n",
            "        [0.1797, 0.1119, 0.8855, 0.5414],\n",
            "        [0.1882, 0.0272, 0.0897, 0.0565],\n",
            "        ...,\n",
            "        [0.7951, 0.9036, 0.4358, 0.5314],\n",
            "        [0.8751, 0.0585, 0.6493, 0.2646],\n",
            "        [0.7754, 0.7098, 0.2099, 0.8888]], requires_grad=True)\n",
            "[{'params': [tensor([[0.7609, 0.7510, 0.1989, 0.7329],\n",
            "        [0.1797, 0.1119, 0.8855, 0.5414],\n",
            "        [0.1882, 0.0272, 0.0897, 0.0565],\n",
            "        ...,\n",
            "        [0.7951, 0.9036, 0.4358, 0.5314],\n",
            "        [0.8751, 0.0585, 0.6493, 0.2646],\n",
            "        [0.7754, 0.7098, 0.2099, 0.8888]], requires_grad=True)], 'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n",
            "#3#\n",
            "tensor([[0.7606, 0.7511, 0.1989, 0.7331],\n",
            "        [0.1800, 0.1116, 0.8859, 0.5410],\n",
            "        [0.1878, 0.0272, 0.0899, 0.0566],\n",
            "        ...,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACqh9KE0k5PK",
        "colab_type": "text"
      },
      "source": [
        "## 問題77"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFlmdfvCokfn",
        "colab_type": "text"
      },
      "source": [
        "https://gotutiyan.hatenablog.com/entry/2020/04/21/182937\n",
        "を参考にしました"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imzZ2iBQlCN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataSet:\n",
        "    def __init__(self,x,y):\n",
        "        self.X = x # 入力\n",
        "        self.y = y # 出力\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X) # データ数(10)を返す\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # index番目の入出力ペアを返す\n",
        "        return self.X[index], self.y[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_rL2GoqvK1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dog-9BOIm11K",
        "colab_type": "code",
        "outputId": "8843c983-7735-4587-8ec7-5c027069d407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# さっき作ったDataSetクラスのインスタンスを作成\n",
        "dataset = DataSet(train_x,train_y)\n",
        "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
        "W_base=np.random.rand(len(train_x[0]),4)\n",
        "W_base=np.matrix(W_base)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "W = torch.tensor(W, dtype=torch.float, requires_grad=True)\n",
        "for i in [1,2,4,8,16,32,64,128]:\n",
        "  print(\"batch_size:\"+str(i))\n",
        "  W=copy.deepcopy(W_base)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=i)\n",
        "  elapsed_time=0\n",
        "  epoch_count=3\n",
        "  for epoch in range(epoch_count):\n",
        "    loss_ave=0\n",
        "    grad_ave=0\n",
        "    start=time.time()\n",
        "    for data_x,data_y in dataloader:\n",
        "      op = optim.SGD([W],lr=0.1)\n",
        "      calc_data = loss(torch.mm(data_x, W), data_y)\n",
        "      loss_ave+=calc_data.item()\n",
        "      op.zero_grad()\n",
        "      calc_data.backward()\n",
        "      grad_ave=torch.add(grad_ave,W.grad)\n",
        "      op.step()\n",
        "    elapsed_time += time.time() - start\n",
        "    loss_ave=loss_ave/len(dataloader)\n",
        "    grad_ave= grad_ave/len(dataloader)\n",
        "    print(\"epoch{} : {} , \\n{}\".format(epoch, loss_ave, grad_ave))\n",
        "  elapsed_time=elapsed_time/epoch_count\n",
        "  print(\"time:{}\".format(elapsed_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6377, 0.7626, 0.5749, 0.3019],\n",
            "        [0.7771, 0.3224, 0.4686, 0.9605],\n",
            "        [0.7146, 0.8979, 0.6751, 0.5185],\n",
            "        ...,\n",
            "        [0.5577, 0.5065, 0.5407, 0.1637],\n",
            "        [0.6493, 0.9939, 0.7065, 0.9970],\n",
            "        [0.6488, 0.4315, 0.8451, 0.5480]], grad_fn=<CopyBackwards>)\n",
            "tensor([[0.6377, 0.7626, 0.5749, 0.3019],\n",
            "        [0.7771, 0.3224, 0.4686, 0.9605],\n",
            "        [0.7146, 0.8979, 0.6751, 0.5185],\n",
            "        ...,\n",
            "        [0.5577, 0.5065, 0.5407, 0.1637],\n",
            "        [0.6493, 0.9939, 0.7065, 0.9970],\n",
            "        [0.6488, 0.4315, 0.8451, 0.5480]], requires_grad=True)\n",
            "batch_size:1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch0 : 0.547920393824924 , \n",
            "tensor([[ 1.5414e-04, -2.2050e-04,  1.8732e-05,  4.7628e-05],\n",
            "        [ 2.9822e-04, -1.0868e-04, -1.6968e-04, -1.9863e-05],\n",
            "        [ 3.1004e-04, -2.1736e-04,  2.8043e-04, -3.7312e-04],\n",
            "        ...,\n",
            "        [-7.4140e-04,  6.7128e-04,  6.5467e-04, -5.8455e-04],\n",
            "        [ 2.2432e-04,  2.6345e-04, -1.2003e-05, -4.7576e-04],\n",
            "        [ 9.7443e-04,  7.2668e-04, -9.5734e-04, -7.4377e-04]])\n",
            "epoch1 : 0.43068812484783503 , \n",
            "tensor([[-3.9391e-05,  1.1125e-05,  1.1750e-04, -8.9239e-05],\n",
            "        [ 1.4866e-04, -2.0241e-04, -3.5982e-05,  8.9732e-05],\n",
            "        [ 2.9594e-05, -2.3067e-04,  3.1331e-04, -1.1224e-04],\n",
            "        ...,\n",
            "        [-5.2252e-05,  2.4495e-04, -1.0182e-04, -9.0874e-05],\n",
            "        [ 2.3750e-04, -1.1014e-04, -1.5745e-04,  3.0094e-05],\n",
            "        [ 2.1100e-04,  3.0615e-04, -1.1718e-04, -3.9997e-04]])\n",
            "epoch2 : 0.40535122854651445 , \n",
            "tensor([[ 8.7492e-08,  3.1830e-05,  7.1064e-05, -1.0298e-04],\n",
            "        [ 8.8389e-05, -1.5995e-04, -2.4692e-05,  9.6249e-05],\n",
            "        [ 8.9392e-06, -1.7982e-04,  2.5522e-04, -8.4343e-05],\n",
            "        ...,\n",
            "        [ 7.4786e-06,  1.3154e-04, -1.3861e-04, -4.1137e-07],\n",
            "        [ 1.8205e-04, -1.1594e-04, -1.4262e-04,  7.6511e-05],\n",
            "        [ 1.4415e-04,  1.9645e-04, -4.6516e-05, -2.9408e-04]])\n",
            "time:4.203697681427002\n",
            "batch_size:2\n",
            "epoch0 : 0.6166566084390923 , \n",
            "tensor([[ 3.4074e-04, -3.7833e-04, -4.8212e-05,  8.5798e-05],\n",
            "        [ 3.8943e-04, -1.8027e-05, -3.0803e-04, -6.3374e-05],\n",
            "        [ 5.2038e-04, -1.8761e-04,  2.1307e-04, -5.4584e-04],\n",
            "        ...,\n",
            "        [-1.2552e-03,  8.8955e-04,  1.2482e-03, -8.8260e-04],\n",
            "        [ 1.2865e-04,  4.9762e-04,  1.6133e-04, -7.8761e-04],\n",
            "        [ 1.5490e-03,  9.4177e-04, -1.5728e-03, -9.1800e-04]])\n",
            "epoch1 : 0.4676490453393794 , \n",
            "tensor([[-2.2476e-05, -8.4812e-05,  1.4561e-04, -3.8322e-05],\n",
            "        [ 2.1257e-04, -2.0300e-04, -6.0829e-05,  5.1261e-05],\n",
            "        [ 8.9016e-05, -2.5500e-04,  3.5817e-04, -1.9218e-04],\n",
            "        ...,\n",
            "        [-2.3175e-04,  4.7063e-04,  4.4354e-05, -2.8323e-04],\n",
            "        [ 2.6711e-04, -3.1221e-06, -1.2612e-04, -1.3787e-04],\n",
            "        [ 3.3434e-04,  5.1619e-04, -2.7196e-04, -5.7857e-04]])\n",
            "epoch2 : 0.4343847449183161 , \n",
            "tensor([[-4.6671e-05, -1.5095e-06,  1.3240e-04, -8.4220e-05],\n",
            "        [ 1.7385e-04, -2.1417e-04, -4.1326e-05,  8.1645e-05],\n",
            "        [ 4.3180e-05, -2.4024e-04,  3.2131e-04, -1.2425e-04],\n",
            "        ...,\n",
            "        [-8.7215e-05,  2.9784e-04, -8.4068e-05, -1.2656e-04],\n",
            "        [ 2.4695e-04, -9.8681e-05, -1.5005e-04,  1.7781e-06],\n",
            "        [ 2.2820e-04,  3.5245e-04, -1.4366e-04, -4.3699e-04]])\n",
            "time:2.155617078145345\n",
            "batch_size:4\n",
            "epoch0 : 0.7037900871343487 , \n",
            "tensor([[ 5.6675e-04, -5.4407e-04, -1.0019e-04,  7.7510e-05],\n",
            "        [ 5.2944e-04,  6.9857e-05, -5.3102e-04, -6.8273e-05],\n",
            "        [ 8.6819e-04, -1.8874e-04,  6.4629e-05, -7.4408e-04],\n",
            "        ...,\n",
            "        [-1.9993e-03,  1.0415e-03,  2.1573e-03, -1.1995e-03],\n",
            "        [-7.2489e-05,  7.0751e-04,  4.5937e-04, -1.0944e-03],\n",
            "        [ 2.4714e-03,  1.1120e-03, -2.5383e-03, -1.0451e-03]])\n",
            "epoch1 : 0.5235658187104087 , \n",
            "tensor([[ 1.3120e-04, -2.5258e-04,  7.9512e-05,  4.1869e-05],\n",
            "        [ 2.5248e-04, -1.2173e-04, -1.0402e-04, -2.6738e-05],\n",
            "        [ 1.9276e-04, -2.0256e-04,  3.6596e-04, -3.5616e-04],\n",
            "        ...,\n",
            "        [-5.2982e-04,  7.3954e-04,  3.5159e-04, -5.6132e-04],\n",
            "        [ 2.4794e-04,  2.4684e-04, -4.3916e-05, -4.5086e-04],\n",
            "        [ 5.5847e-04,  7.8154e-04, -5.4951e-04, -7.9049e-04]])\n",
            "epoch2 : 0.4771735390507432 , \n",
            "tensor([[ 1.0555e-06, -1.2134e-04,  1.4499e-04, -2.4706e-05],\n",
            "        [ 2.3043e-04, -1.9369e-04, -7.4295e-05,  3.7554e-05],\n",
            "        [ 1.1452e-04, -2.4995e-04,  3.5667e-04, -2.2124e-04],\n",
            "        ...,\n",
            "        [-2.9243e-04,  5.3806e-04,  9.7782e-05, -3.4342e-04],\n",
            "        [ 2.5723e-04,  4.1234e-05, -1.0242e-04, -1.9605e-04],\n",
            "        [ 3.6192e-04,  5.8068e-04, -3.1401e-04, -6.2859e-04]])\n",
            "time:1.1120000680287678\n",
            "batch_size:8\n",
            "epoch0 : 0.8024548761278927 , \n",
            "tensor([[ 7.5358e-04, -7.0386e-04, -6.3937e-05,  1.4216e-05],\n",
            "        [ 7.1727e-04,  1.4499e-04, -8.8570e-04,  2.3445e-05],\n",
            "        [ 1.3159e-03, -2.5291e-04, -1.6012e-04, -9.0290e-04],\n",
            "        ...,\n",
            "        [-3.0038e-03,  1.0779e-03,  3.4682e-03, -1.5423e-03],\n",
            "        [-3.6639e-04,  8.0864e-04,  8.8695e-04, -1.3292e-03],\n",
            "        [ 3.8198e-03,  1.2219e-03, -3.9319e-03, -1.1098e-03]])\n",
            "epoch1 : 0.6010638698098991 , \n",
            "tensor([[ 3.8506e-04, -4.2255e-04, -7.2682e-05,  1.1018e-04],\n",
            "        [ 3.2004e-04, -1.7753e-05, -1.5869e-04, -1.4360e-04],\n",
            "        [ 3.7268e-04, -1.2393e-04,  3.4988e-04, -5.9863e-04],\n",
            "        ...,\n",
            "        [-1.0012e-03,  9.9511e-04,  8.5136e-04, -8.4529e-04],\n",
            "        [ 2.4777e-04,  5.4909e-04,  6.5144e-05, -8.6201e-04],\n",
            "        [ 1.0319e-03,  1.0256e-03, -1.0957e-03, -9.6177e-04]])\n",
            "epoch2 : 0.5390961551146504 , \n",
            "tensor([[ 1.8377e-04, -3.0213e-04,  5.7704e-05,  6.0656e-05],\n",
            "        [ 2.5517e-04, -9.4086e-05, -1.1138e-04, -4.9707e-05],\n",
            "        [ 2.0338e-04, -1.7385e-04,  3.7662e-04, -4.0616e-04],\n",
            "        ...,\n",
            "        [-6.0596e-04,  8.0288e-04,  4.3578e-04, -6.3271e-04],\n",
            "        [ 2.7345e-04,  3.1094e-04, -3.6040e-05, -5.4835e-04],\n",
            "        [ 6.3665e-04,  8.4606e-04, -6.4289e-04, -8.3981e-04]])\n",
            "time:0.585284153620402\n",
            "batch_size:16\n",
            "epoch0 : 0.9073494278385253 , \n",
            "tensor([[ 0.0008, -0.0009,  0.0001, -0.0001],\n",
            "        [ 0.0009,  0.0003, -0.0015,  0.0003],\n",
            "        [ 0.0019, -0.0004, -0.0005, -0.0010],\n",
            "        ...,\n",
            "        [-0.0042,  0.0010,  0.0053, -0.0021],\n",
            "        [-0.0009,  0.0008,  0.0015, -0.0015],\n",
            "        [ 0.0056,  0.0013, -0.0057, -0.0012]])\n",
            "epoch1 : 0.69486176749011 , \n",
            "tensor([[ 6.6819e-04, -5.6013e-04, -2.1380e-04,  1.0575e-04],\n",
            "        [ 5.0243e-04,  6.6883e-06, -2.7358e-04, -2.3554e-04],\n",
            "        [ 7.5019e-04, -1.4922e-04,  2.4434e-04, -8.4531e-04],\n",
            "        ...,\n",
            "        [-1.8267e-03,  1.2186e-03,  1.6477e-03, -1.0396e-03],\n",
            "        [ 1.2919e-04,  7.5341e-04,  3.1366e-04, -1.1963e-03],\n",
            "        [ 1.9018e-03,  1.2345e-03, -2.1153e-03, -1.0211e-03]])\n",
            "epoch2 : 0.6219561604593329 , \n",
            "tensor([[ 4.6210e-04, -4.6745e-04, -1.0560e-04,  1.1095e-04],\n",
            "        [ 3.4637e-04,  1.7460e-06, -1.8313e-04, -1.6499e-04],\n",
            "        [ 4.3982e-04, -1.1079e-04,  3.3565e-04, -6.6468e-04],\n",
            "        ...,\n",
            "        [-1.1515e-03,  1.0519e-03,  1.0121e-03, -9.1244e-04],\n",
            "        [ 2.3684e-04,  6.1134e-04,  1.0717e-04, -9.5535e-04],\n",
            "        [ 1.1844e-03,  1.0789e-03, -1.2710e-03, -9.9224e-04]])\n",
            "time:0.32346073786417645\n",
            "batch_size:32\n",
            "epoch0 : 1.0153675505857982 , \n",
            "tensor([[ 0.0008, -0.0010,  0.0005, -0.0003],\n",
            "        [ 0.0011,  0.0005, -0.0024,  0.0008],\n",
            "        [ 0.0024, -0.0005, -0.0010, -0.0010],\n",
            "        ...,\n",
            "        [-0.0055,  0.0005,  0.0078, -0.0029],\n",
            "        [-0.0016,  0.0008,  0.0023, -0.0015],\n",
            "        [ 0.0077,  0.0011, -0.0075, -0.0013]])\n",
            "epoch1 : 0.7975149712341274 , \n",
            "tensor([[ 8.4876e-04, -6.7960e-04, -2.0952e-04,  4.0362e-05],\n",
            "        [ 7.7548e-04, -5.3423e-05, -5.3031e-04, -1.9175e-04],\n",
            "        [ 1.2935e-03, -2.8992e-04, -3.8937e-06, -9.9971e-04],\n",
            "        ...,\n",
            "        [-3.0637e-03,  1.4007e-03,  2.9296e-03, -1.2667e-03],\n",
            "        [-2.3973e-04,  8.1786e-04,  8.0775e-04, -1.3859e-03],\n",
            "        [ 3.4188e-03,  1.4236e-03, -3.8146e-03, -1.0278e-03]])\n",
            "epoch2 : 0.7187373595323391 , \n",
            "tensor([[ 7.3428e-04, -5.9569e-04, -2.3155e-04,  9.2966e-05],\n",
            "        [ 5.6118e-04, -7.7182e-07, -3.1605e-04, -2.4436e-04],\n",
            "        [ 8.6517e-04, -1.7258e-04,  2.0491e-04, -8.9750e-04],\n",
            "        ...,\n",
            "        [-2.0848e-03,  1.2692e-03,  1.8951e-03, -1.0795e-03],\n",
            "        [ 7.0832e-05,  7.7876e-04,  4.0859e-04, -1.2582e-03],\n",
            "        [ 2.1743e-03,  1.2873e-03, -2.4381e-03, -1.0235e-03]])\n",
            "time:0.18898542722066244\n",
            "batch_size:64\n",
            "epoch0 : 1.121887364787256 , \n",
            "tensor([[ 0.0007, -0.0013,  0.0010, -0.0004],\n",
            "        [ 0.0011,  0.0010, -0.0036,  0.0014],\n",
            "        [ 0.0029, -0.0005, -0.0015, -0.0009],\n",
            "        ...,\n",
            "        [-0.0064, -0.0002,  0.0105, -0.0039],\n",
            "        [-0.0022,  0.0009,  0.0029, -0.0015],\n",
            "        [ 0.0096,  0.0009, -0.0089, -0.0015]])\n",
            "epoch1 : 0.9077691946200982 , \n",
            "tensor([[ 8.4753e-04, -8.3253e-04,  7.1334e-05, -8.6333e-05],\n",
            "        [ 1.0042e-03,  3.9846e-05, -1.1703e-03,  1.2633e-04],\n",
            "        [ 1.9420e-03, -4.2625e-04, -4.7692e-04, -1.0388e-03],\n",
            "        ...,\n",
            "        [-4.5307e-03,  1.2680e-03,  5.0979e-03, -1.8352e-03],\n",
            "        [-9.4986e-04,  8.2556e-04,  1.6005e-03, -1.4762e-03],\n",
            "        [ 5.7624e-03,  1.4598e-03, -6.1234e-03, -1.0988e-03]])\n",
            "epoch2 : 0.8233023881912231 , \n",
            "tensor([[ 8.7066e-04, -7.1194e-04, -1.7438e-04,  1.5655e-05],\n",
            "        [ 8.4411e-04, -6.3659e-05, -6.2983e-04, -1.5063e-04],\n",
            "        [ 1.4425e-03, -3.3061e-04, -8.8164e-05, -1.0237e-03],\n",
            "        ...,\n",
            "        [-3.4137e-03,  1.4245e-03,  3.3446e-03, -1.3553e-03],\n",
            "        [-3.7684e-04,  8.1927e-04,  9.7463e-04, -1.4171e-03],\n",
            "        [ 3.8873e-03,  1.4624e-03, -4.3149e-03, -1.0348e-03]])\n",
            "time:0.12428641319274902\n",
            "batch_size:128\n",
            "epoch0 : 1.2157465943268366 , \n",
            "tensor([[ 0.0007, -0.0015,  0.0014, -0.0006],\n",
            "        [ 0.0011,  0.0015, -0.0047,  0.0020],\n",
            "        [ 0.0032, -0.0005, -0.0018, -0.0008],\n",
            "        ...,\n",
            "        [-0.0070, -0.0009,  0.0129, -0.0049],\n",
            "        [-0.0027,  0.0009,  0.0033, -0.0016],\n",
            "        [ 0.0108,  0.0005, -0.0095, -0.0018]])\n",
            "epoch1 : 1.0242867136285418 , \n",
            "tensor([[ 0.0007, -0.0010,  0.0006, -0.0003],\n",
            "        [ 0.0012,  0.0005, -0.0024,  0.0007],\n",
            "        [ 0.0026, -0.0005, -0.0011, -0.0010],\n",
            "        ...,\n",
            "        [-0.0059,  0.0006,  0.0082, -0.0029],\n",
            "        [-0.0018,  0.0008,  0.0025, -0.0015],\n",
            "        [ 0.0083,  0.0012, -0.0082, -0.0013]])\n",
            "epoch2 : 0.9340385432754245 , \n",
            "tensor([[ 8.0480e-04, -8.6467e-04,  1.8428e-04, -1.2441e-04],\n",
            "        [ 1.0442e-03,  9.5721e-05, -1.3758e-03,  2.3589e-04],\n",
            "        [ 2.1160e-03, -4.5980e-04, -6.1323e-04, -1.0430e-03],\n",
            "        ...,\n",
            "        [-4.8983e-03,  1.1721e-03,  5.7567e-03, -2.0305e-03],\n",
            "        [-1.1511e-03,  8.2507e-04,  1.8318e-03, -1.5058e-03],\n",
            "        [ 6.3849e-03,  1.4165e-03, -6.6727e-03, -1.1287e-03]])\n",
            "time:0.09475008646647136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGHMWzXBBkCz",
        "colab_type": "text"
      },
      "source": [
        "## 問題78\n",
        "https://qiita.com/elm200/items/46633430c456dd90f1e3\n",
        "を参考にしました"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7U_U6arFEvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_gpu(e):\n",
        "    if torch.cuda.is_available():\n",
        "        return e.cuda()\n",
        "    return e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcEfzUKeFODq",
        "colab_type": "code",
        "outputId": "fb75f54d-75ff-4dee-9a94-abfcd85f7416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# さっき作ったDataSetクラスのインスタンスを作成\n",
        "dataset = DataSet(train_x,train_y)\n",
        "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
        "W_base=np.random.rand(len(train_x[0]),4)\n",
        "W_base=np.matrix(W_base)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "W = torch.tensor(W, dtype=torch.float, requires_grad=True)\n",
        "W_base=try_gpu(W_base)\n",
        "print(W_base)\n",
        "for i in [1,2,4,8,16,32,64,128]:\n",
        "  print(\"batch_size:\"+str(i))\n",
        "  W=copy.deepcopy(W_base)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=i)\n",
        "  elapsed_time=0\n",
        "  epoch_count=3\n",
        "  for epoch in range(epoch_count):\n",
        "    loss_ave=0\n",
        "    grad_ave=0\n",
        "    start=time.time()\n",
        "    for data_x,data_y in dataloader:\n",
        "      data_x_gpu=try_gpu(data_x)\n",
        "      data_y_gpu=try_gpu(data_y)\n",
        "      op = optim.SGD([W],lr=0.1)\n",
        "      op=try_gpu(op)\n",
        "      calc_data = loss(torch.mm(data_x_gpu, W), data_y_gpu)\n",
        "      loss_ave+=calc_data.item()\n",
        "      op.zero_grad()\n",
        "      calc_data.backward()\n",
        "      grad_ave=torch.add(grad_ave,W.grad)\n",
        "      op.step()\n",
        "    elapsed_time += time.time() - start\n",
        "    loss_ave=loss_ave/len(dataloader)\n",
        "    grad_ave= grad_ave/len(dataloader)\n",
        "    print(\"epoch{} : {} , \\n{}\".format(epoch, loss_ave, grad_ave))\n",
        "  elapsed_time=elapsed_time/epoch_count\n",
        "  print(\"time:{}\".format(elapsed_time))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3072, 0.7051, 0.6811, 0.7994],\n",
            "        [0.5377, 0.7834, 0.7191, 0.6039],\n",
            "        [0.6407, 0.3233, 0.1465, 0.1616],\n",
            "        ...,\n",
            "        [0.5239, 0.6132, 0.4925, 0.9845],\n",
            "        [0.2850, 0.3398, 0.6181, 0.3581],\n",
            "        [0.0059, 0.7152, 0.0971, 0.0223]], grad_fn=<CopyBackwards>)\n",
            "tensor([[0.3072, 0.7051, 0.6811, 0.7994],\n",
            "        [0.5377, 0.7834, 0.7191, 0.6039],\n",
            "        [0.6407, 0.3233, 0.1465, 0.1616],\n",
            "        ...,\n",
            "        [0.5239, 0.6132, 0.4925, 0.9845],\n",
            "        [0.2850, 0.3398, 0.6181, 0.3581],\n",
            "        [0.0059, 0.7152, 0.0971, 0.0223]], requires_grad=True)\n",
            "batch_size:1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch0 : 0.5518120263895131 , \n",
            "tensor([[ 6.8664e-05, -2.4212e-04,  8.4974e-05,  8.8482e-05],\n",
            "        [ 2.2113e-04, -8.7727e-05, -2.4551e-05, -1.0886e-04],\n",
            "        [ 5.2918e-04, -3.2585e-04,  3.0249e-04, -5.0582e-04],\n",
            "        ...,\n",
            "        [-7.5952e-04,  6.4854e-04,  5.5120e-04, -4.4021e-04],\n",
            "        [ 1.6947e-04,  2.5071e-04,  9.1583e-05, -5.1176e-04],\n",
            "        [ 1.0149e-03,  7.6538e-04, -9.1810e-04, -8.6223e-04]])\n",
            "epoch1 : 0.43131260080418377 , \n",
            "tensor([[-8.3400e-05, -2.7614e-05,  1.6946e-04, -5.8448e-05],\n",
            "        [ 9.6527e-05, -1.6883e-04,  1.7651e-05,  5.4651e-05],\n",
            "        [ 7.8633e-05, -2.6130e-04,  3.1322e-04, -1.3056e-04],\n",
            "        ...,\n",
            "        [-5.7653e-05,  2.2854e-04, -1.3110e-04, -3.9790e-05],\n",
            "        [ 2.2377e-04, -1.2241e-04, -1.1489e-04,  1.3527e-05],\n",
            "        [ 2.0319e-04,  3.7069e-04, -1.5656e-04, -4.1732e-04]])\n",
            "epoch2 : 0.4053954146024475 , \n",
            "tensor([[-2.5053e-05,  6.0892e-06,  1.0195e-04, -8.2984e-05],\n",
            "        [ 5.0228e-05, -1.3006e-04,  5.8644e-06,  7.3972e-05],\n",
            "        [ 3.3519e-05, -1.9134e-04,  2.4452e-04, -8.6694e-05],\n",
            "        ...,\n",
            "        [ 1.9180e-06,  1.2095e-04, -1.5555e-04,  3.2686e-05],\n",
            "        [ 1.7501e-04, -1.2267e-04, -1.1589e-04,  6.3550e-05],\n",
            "        [ 1.2283e-04,  2.5244e-04, -7.2416e-05, -3.0285e-04]])\n",
            "time:5.406732638676961\n",
            "batch_size:2\n",
            "epoch0 : 0.6222964009721005 , \n",
            "tensor([[ 2.5328e-04, -3.5867e-04, -1.3020e-05,  1.1841e-04],\n",
            "        [ 2.8961e-04, -1.5282e-05, -1.0073e-04, -1.7359e-04],\n",
            "        [ 8.4644e-04, -3.2500e-04,  2.3057e-04, -7.5201e-04],\n",
            "        ...,\n",
            "        [-1.2659e-03,  8.6798e-04,  1.0907e-03, -6.9281e-04],\n",
            "        [ 5.6165e-05,  5.0288e-04,  2.7853e-04, -8.3758e-04],\n",
            "        [ 1.5992e-03,  9.3917e-04, -1.4232e-03, -1.1152e-03]])\n",
            "epoch1 : 0.46959888928372845 , \n",
            "tensor([[-1.0882e-04, -1.2862e-04,  2.3079e-04,  6.6475e-06],\n",
            "        [ 1.5190e-04, -1.7462e-04,  3.3247e-05, -1.0520e-05],\n",
            "        [ 1.9555e-04, -3.2819e-04,  3.8231e-04, -2.4967e-04],\n",
            "        ...,\n",
            "        [-2.3872e-04,  4.4187e-04, -8.9766e-06, -1.9418e-04],\n",
            "        [ 2.3318e-04, -2.8034e-05, -4.2412e-05, -1.6274e-04],\n",
            "        [ 3.5306e-04,  5.8874e-04, -3.2582e-04, -6.1598e-04]])\n",
            "epoch2 : 0.435220331690413 , \n",
            "tensor([[-9.7309e-05, -4.3953e-05,  1.9223e-04, -5.0968e-05],\n",
            "        [ 1.1953e-04, -1.8090e-04,  2.0769e-05,  4.0605e-05],\n",
            "        [ 1.0422e-04, -2.7898e-04,  3.2516e-04, -1.5041e-04],\n",
            "        ...,\n",
            "        [-9.4259e-05,  2.7989e-04, -1.1815e-04, -6.7483e-05],\n",
            "        [ 2.3005e-04, -1.1438e-04, -1.0035e-04, -1.5327e-05],\n",
            "        [ 2.2508e-04,  4.1946e-04, -1.8632e-04, -4.5822e-04]])\n",
            "time:2.7476210594177246\n",
            "batch_size:4\n",
            "epoch0 : 0.7108153231863021 , \n",
            "tensor([[ 5.3167e-04, -4.6343e-04, -1.6304e-04,  9.4800e-05],\n",
            "        [ 3.8333e-04,  5.6895e-05, -2.5595e-04, -1.8428e-04],\n",
            "        [ 1.3203e-03, -3.4082e-04,  5.0413e-05, -1.0299e-03],\n",
            "        ...,\n",
            "        [-1.9835e-03,  1.0391e-03,  1.9111e-03, -9.6673e-04],\n",
            "        [-1.3664e-04,  7.5108e-04,  5.3883e-04, -1.1533e-03],\n",
            "        [ 2.5029e-03,  1.0419e-03, -2.1823e-03, -1.3625e-03]])\n",
            "epoch1 : 0.5276534265948705 , \n",
            "tensor([[-1.1624e-05, -2.7685e-04,  2.0111e-04,  8.7359e-05],\n",
            "        [ 1.9069e-04, -1.0857e-04,  4.3037e-05, -1.2515e-04],\n",
            "        [ 3.8153e-04, -3.2273e-04,  4.1981e-04, -4.7861e-04],\n",
            "        ...,\n",
            "        [-5.4055e-04,  6.9438e-04,  2.6295e-04, -4.1679e-04],\n",
            "        [ 1.7556e-04,  2.1526e-04,  1.0395e-04, -4.9477e-04],\n",
            "        [ 6.1527e-04,  8.5086e-04, -6.0351e-04, -8.6262e-04]])\n",
            "epoch2 : 0.4794917700559174 , \n",
            "tensor([[-9.7635e-05, -1.6264e-04,  2.3929e-04,  2.0980e-05],\n",
            "        [ 1.6944e-04, -1.6966e-04,  3.2624e-05, -3.2411e-05],\n",
            "        [ 2.3848e-04, -3.3491e-04,  3.8828e-04, -2.9185e-04],\n",
            "        ...,\n",
            "        [-3.0041e-04,  5.0624e-04,  3.7554e-05, -2.4339e-04],\n",
            "        [ 2.1621e-04,  1.3795e-05, -6.5930e-06, -2.2341e-04],\n",
            "        [ 3.8812e-04,  6.5307e-04, -3.6812e-04, -6.7307e-04]])\n",
            "time:1.4455440839131672\n",
            "batch_size:8\n",
            "epoch0 : 0.8100825985949375 , \n",
            "tensor([[ 8.5827e-04, -5.5621e-04, -3.1528e-04,  1.3217e-05],\n",
            "        [ 4.9647e-04,  1.2150e-04, -5.5118e-04, -6.6779e-05],\n",
            "        [ 1.9313e-03, -4.0585e-04, -2.5469e-04, -1.2707e-03],\n",
            "        ...,\n",
            "        [-2.9228e-03,  1.1136e-03,  3.0907e-03, -1.2815e-03],\n",
            "        [-3.8291e-04,  9.0274e-04,  8.4909e-04, -1.3689e-03],\n",
            "        [ 3.7796e-03,  1.0608e-03, -3.2281e-03, -1.6122e-03]])\n",
            "epoch1 : 0.6077220914048884 , \n",
            "tensor([[ 2.0931e-04, -4.0248e-04,  4.8368e-05,  1.4480e-04],\n",
            "        [ 2.4332e-04, -1.8997e-05,  5.4761e-05, -2.7908e-04],\n",
            "        [ 6.6393e-04, -2.6927e-04,  4.0430e-04, -7.9896e-04],\n",
            "        ...,\n",
            "        [-1.0243e-03,  9.4531e-04,  7.1226e-04, -6.3323e-04],\n",
            "        [ 1.3193e-04,  5.3413e-04,  2.6831e-04, -9.3437e-04],\n",
            "        [ 1.1239e-03,  1.0571e-03, -1.0945e-03, -1.0865e-03]])\n",
            "epoch2 : 0.5437829218704454 , \n",
            "tensor([[ 2.8529e-05, -3.1625e-04,  1.8404e-04,  1.0369e-04],\n",
            "        [ 1.9272e-04, -8.6272e-05,  5.0434e-05, -1.5689e-04],\n",
            "        [ 4.1474e-04, -3.0273e-04,  4.3394e-04, -5.4595e-04],\n",
            "        ...,\n",
            "        [-6.1773e-04,  7.5420e-04,  3.3870e-04, -4.7517e-04],\n",
            "        [ 1.9033e-04,  2.7975e-04,  1.3049e-04, -6.0057e-04],\n",
            "        [ 7.0313e-04,  9.0973e-04, -6.8976e-04, -9.2310e-04]])\n",
            "time:0.7516520818074545\n",
            "batch_size:16\n",
            "epoch0 : 0.9142414061519915 , \n",
            "tensor([[ 0.0012, -0.0006, -0.0004, -0.0001],\n",
            "        [ 0.0006,  0.0002, -0.0011,  0.0003],\n",
            "        [ 0.0027, -0.0005, -0.0007, -0.0014],\n",
            "        ...,\n",
            "        [-0.0040,  0.0011,  0.0048, -0.0018],\n",
            "        [-0.0008,  0.0010,  0.0013, -0.0014],\n",
            "        [ 0.0055,  0.0010, -0.0045, -0.0020]])\n",
            "epoch1 : 0.7033704828894781 , \n",
            "tensor([[ 5.3907e-04, -4.7995e-04, -1.9534e-04,  1.3623e-04],\n",
            "        [ 3.8039e-04,  4.8005e-06,  1.3281e-05, -3.9847e-04],\n",
            "        [ 1.1758e-03, -2.9684e-04,  2.3351e-04, -1.1125e-03],\n",
            "        ...,\n",
            "        [-1.8670e-03,  1.1879e-03,  1.4279e-03, -7.4880e-04],\n",
            "        [ 2.0375e-06,  7.8564e-04,  4.8748e-04, -1.2752e-03],\n",
            "        [ 1.9766e-03,  1.1713e-03, -1.9221e-03, -1.2258e-03]])\n",
            "epoch2 : 0.6292640539165029 , \n",
            "tensor([[ 2.8532e-04, -4.3160e-04,  2.8998e-06,  1.4338e-04],\n",
            "        [ 2.6040e-04, -2.3920e-06,  4.9629e-05, -3.0764e-04],\n",
            "        [ 7.5691e-04, -2.5805e-04,  3.8354e-04, -8.8240e-04],\n",
            "        ...,\n",
            "        [-1.1774e-03,  1.0036e-03,  8.5626e-04, -6.8248e-04],\n",
            "        [ 1.1339e-04,  6.0528e-04,  3.1540e-04, -1.0341e-03],\n",
            "        [ 1.2807e-03,  1.0935e-03, -1.2423e-03, -1.1318e-03]])\n",
            "time:0.40985973676045734\n",
            "batch_size:32\n",
            "epoch0 : 1.021302395773505 , \n",
            "tensor([[ 0.0014, -0.0008, -0.0003, -0.0004],\n",
            "        [ 0.0006,  0.0005, -0.0020,  0.0009],\n",
            "        [ 0.0034, -0.0006, -0.0012, -0.0016],\n",
            "        ...,\n",
            "        [-0.0049,  0.0007,  0.0070, -0.0028],\n",
            "        [-0.0014,  0.0010,  0.0018, -0.0014],\n",
            "        [ 0.0074,  0.0008, -0.0058, -0.0025]])\n",
            "epoch1 : 0.8052899421689039 , \n",
            "tensor([[ 9.0054e-04, -5.3386e-04, -4.4233e-04,  7.5645e-05],\n",
            "        [ 6.0645e-04, -5.9590e-05, -1.8324e-04, -3.6363e-04],\n",
            "        [ 1.9261e-03, -4.3717e-04, -1.5620e-04, -1.3327e-03],\n",
            "        ...,\n",
            "        [-3.0996e-03,  1.4217e-03,  2.5757e-03, -8.9774e-04],\n",
            "        [-2.9776e-04,  9.1054e-04,  8.2021e-04, -1.4330e-03],\n",
            "        [ 3.3429e-03,  1.2337e-03, -3.1922e-03, -1.3844e-03]])\n",
            "epoch2 : 0.7275282214144747 , \n",
            "tensor([[ 6.3164e-04, -4.9845e-04, -2.5721e-04,  1.2401e-04],\n",
            "        [ 4.2477e-04, -1.4788e-06, -1.1874e-05, -4.1142e-04],\n",
            "        [ 1.3318e-03, -3.1937e-04,  1.6639e-04, -1.1788e-03],\n",
            "        ...,\n",
            "        [-2.1264e-03,  1.2444e-03,  1.6497e-03, -7.6770e-04],\n",
            "        [-5.0515e-05,  8.2493e-04,  5.5877e-04, -1.3332e-03],\n",
            "        [ 2.2313e-03,  1.1940e-03, -2.1715e-03, -1.2538e-03]])\n",
            "time:0.23987579345703125\n",
            "batch_size:64\n",
            "epoch0 : 1.1316245016223656 , \n",
            "tensor([[ 1.5662e-03, -9.0525e-04,  5.2043e-06, -6.6613e-04],\n",
            "        [ 4.1903e-04,  8.8168e-04, -3.1644e-03,  1.8637e-03],\n",
            "        [ 4.0601e-03, -6.4234e-04, -1.7098e-03, -1.7080e-03],\n",
            "        ...,\n",
            "        [-5.4931e-03,  6.5277e-05,  9.5879e-03, -4.1601e-03],\n",
            "        [-1.9311e-03,  1.1113e-03,  2.2215e-03, -1.4017e-03],\n",
            "        [ 9.3336e-03,  5.8306e-04, -6.7072e-03, -3.2095e-03]])\n",
            "epoch1 : 0.909855156244632 , \n",
            "tensor([[ 1.2045e-03, -6.1093e-04, -5.4359e-04, -4.9996e-05],\n",
            "        [ 7.8358e-04,  1.9251e-06, -7.6929e-04, -1.6209e-05],\n",
            "        [ 2.8294e-03, -5.8125e-04, -7.6866e-04, -1.4795e-03],\n",
            "        ...,\n",
            "        [-4.4525e-03,  1.3827e-03,  4.4827e-03, -1.4129e-03],\n",
            "        [-8.4216e-04,  9.8071e-04,  1.3216e-03, -1.4601e-03],\n",
            "        [ 5.3893e-03,  1.1599e-03, -4.7966e-03, -1.7526e-03]])\n",
            "epoch2 : 0.830354199438038 , \n",
            "tensor([[ 9.8402e-04, -5.4873e-04, -4.8861e-04,  5.3317e-05],\n",
            "        [ 6.6466e-04, -7.4184e-05, -2.6981e-04, -3.2066e-04],\n",
            "        [ 2.1370e-03, -4.7872e-04, -2.8263e-04, -1.3756e-03],\n",
            "        ...,\n",
            "        [-3.4387e-03,  1.4635e-03,  2.9438e-03, -9.6860e-04],\n",
            "        [-4.0450e-04,  9.2683e-04,  9.2936e-04, -1.4517e-03],\n",
            "        [ 3.7503e-03,  1.2426e-03, -3.5494e-03, -1.4434e-03]])\n",
            "time:0.14752650260925293\n",
            "batch_size:128\n",
            "epoch0 : 1.2398447209880465 , \n",
            "tensor([[ 1.6913e-03, -1.0425e-03,  4.0117e-04, -1.0500e-03],\n",
            "        [ 9.5525e-05,  1.3337e-03, -4.3418e-03,  2.9126e-03],\n",
            "        [ 4.4756e-03, -6.4257e-04, -2.0030e-03, -1.8300e-03],\n",
            "        ...,\n",
            "        [-5.5457e-03, -6.4273e-04,  1.1954e-02, -5.7652e-03],\n",
            "        [-2.3342e-03,  1.1693e-03,  2.5487e-03, -1.3837e-03],\n",
            "        [ 1.0801e-02,  2.8756e-04, -7.1279e-03, -3.9611e-03]])\n",
            "epoch1 : 1.0196249513399034 , \n",
            "tensor([[ 0.0014, -0.0007, -0.0004, -0.0003],\n",
            "        [ 0.0008,  0.0004, -0.0019,  0.0008],\n",
            "        [ 0.0037, -0.0007, -0.0014, -0.0016],\n",
            "        ...,\n",
            "        [-0.0055,  0.0008,  0.0072, -0.0025],\n",
            "        [-0.0015,  0.0011,  0.0019, -0.0014],\n",
            "        [ 0.0078,  0.0009, -0.0062, -0.0024]])\n",
            "epoch2 : 0.9341812836272376 , \n",
            "tensor([[ 1.2450e-03, -6.2480e-04, -5.2827e-04, -9.1968e-05],\n",
            "        [ 8.0062e-04,  4.6885e-05, -9.5489e-04,  1.0738e-04],\n",
            "        [ 3.0670e-03, -6.1709e-04, -9.3127e-04, -1.5187e-03],\n",
            "        ...,\n",
            "        [-4.7649e-03,  1.3154e-03,  5.0543e-03, -1.6048e-03],\n",
            "        [-9.9859e-04,  9.9750e-04,  1.4711e-03, -1.4700e-03],\n",
            "        [ 5.9367e-03,  1.0947e-03, -5.1547e-03, -1.8766e-03]])\n",
            "time:0.10324970881144206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqQWkgn5U_qk",
        "colab_type": "text"
      },
      "source": [
        "## 問題79"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMNEQcUVQfiJ",
        "colab_type": "text"
      },
      "source": [
        "https://qiita.com/sudamasahiko/items/b54fed1ffe8bb6d48818\n",
        "を参考にしました"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuddshOWpq0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch8/train_x.pickle\",'rb') as f:\n",
        "  train_x=pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch8/train_y.pickle\",'rb') as f:\n",
        "  train_y=pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch8/test_x.pickle\",'rb') as f:\n",
        "  test_x=pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch8/test_y.pickle\",'rb') as f:\n",
        "  test_y=pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch8/valid_x.pickle\",'rb') as f:\n",
        "  valid_x=pickle.load(f)\n",
        "with open(drive_root_dir+\"/Colab Notebooks/ch8/valid_y.pickle\",'rb') as f:\n",
        "  valid_y=pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK9vXzNxv2xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV0IHNJyuETB",
        "colab_type": "text"
      },
      "source": [
        "http://murayama.hatenablog.com/entry/2017/11/25/231609\n",
        "kamingは一様分布っぽい？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eZhFszdwI4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,i_size,h1_size,h2_size,o_size):\n",
        "    super().__init__()\n",
        "    self.fc1=nn.Linear(i_size,h1_size)\n",
        "    self.fc2=nn.Linear(h1_size,h2_size)\n",
        "    self.fc3=nn.Linear(h2_size,o_size)\n",
        "    nn.init.kaiming_normal_(self.fc1.weight)\n",
        "    nn.init.kaiming_normal_(self.fc2.weight)\n",
        "    nn.init.kaiming_normal_(self.fc3.weight)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.fc1(x)\n",
        "    x=self.fc2(x)\n",
        "    x=F.softmax(self.fc3(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKeGuAu1cF_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "dae95547-e2e7-4156-ae68-3b9acf1e164a"
      },
      "source": [
        "net = Net(300,200,100,4)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "var_train_x = Variable(torch.tensor(train_x).float(), requires_grad=True)\n",
        "tensor_train_y = torch.tensor(train_y)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0167,  0.0259, -0.0020,  ...,  0.0004, -0.0198, -0.0123],\n",
            "        [ 0.0415, -0.0301,  0.0054,  ..., -0.0056, -0.0415,  0.0316],\n",
            "        [-0.0676,  0.0049, -0.0248,  ...,  0.0519, -0.0135,  0.0421],\n",
            "        ...,\n",
            "        [-0.0112, -0.0190, -0.0305,  ...,  0.0143,  0.0092, -0.0319],\n",
            "        [-0.0819,  0.0393, -0.0393,  ..., -0.0587,  0.0172, -0.0754],\n",
            "        [-0.0023, -0.0276, -0.1122,  ...,  0.0680,  0.1881, -0.0139]],\n",
            "       requires_grad=True)\n",
            "tensor([2, 2, 0,  ..., 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDp5Sq0acQBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a628bd23-2007-4255-b2a9-73071fdff03c"
      },
      "source": [
        "for i in range(3000):\n",
        "    optimizer.zero_grad()\n",
        "    output = net(var_train_x)\n",
        "    loss = criterion(output, tensor_train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAIYf0kgf-Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(x,net):\n",
        "  preds=net(x).detach().numpy()\n",
        "  max_i=np.argmax(preds)\n",
        "  return max_i\n",
        "def calc_accuracy(x,y,net):\n",
        "  count=0\n",
        "  for i in range(len(x)):\n",
        "    pre = predict(x[i],net)\n",
        "    if y[i] == pre:\n",
        "      count+=1\n",
        "  return count/len(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3e48OS5hG_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7b1df8ec-eb11-4cf8-abe8-6de3b3198920"
      },
      "source": [
        "print(calc_accuracy(var_train_x,tensor_train_y,net))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7628451099672438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQleaxpMhPNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d068693f-65b7-4ee0-e52f-b589f7c58713"
      },
      "source": [
        "var_test_x = Variable(torch.tensor(test_x).float(), requires_grad=True)\n",
        "tensor_test_y = torch.tensor(test_y)\n",
        "print(calc_accuracy(var_test_x,tensor_test_y,net))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7790262172284644\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}